{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson 6 - Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hello, world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called 'hello_constant'\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# tf.constant() is called a constant tensor\n",
    "# A \"TensorFlow Session\", as shown above, is an environment for running a graph, \n",
    "# here, evaluate the tensor in a session.\n",
    "# The code creates a session instance, sess, using tf.Session. The sess.run() function then evaluates the tensor and returns the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Deferent size of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A is a 0-dimensional int32 tensor\n",
    "A = tf.constant(1234) \n",
    "# B is a 1-dimensional int32 tensor\n",
    "B = tf.constant([123,456,789]) \n",
    " # C is a 2-dimensional int32 tensor\n",
    "C = tf.constant([ [123,456,789], [222,333,444] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input : using  tf.placeholder() and feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "tf.placeholder() returns a tensor that gets its value from data passed to the tf.session.run() function, allowing you to set the input right before the session runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello New World\n"
     ]
    }
   ],
   "source": [
    "# Sessionâ€™s feed_dict\n",
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello New World'})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test String\n"
     ]
    }
   ],
   "source": [
    "# It's also possible to set more than one tensor using feed_dict as shown below\n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Addition\n",
    "x = tf.add(5, 2)  # 7\n",
    "# Subtraction and Multiplication\n",
    "x = tf.subtract(10, 4) # 6\n",
    "y = tf.multiply(2, 5)  # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sub_2:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting types, tf.cast()\n",
    "tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1))   # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# example quiz\n",
    "import tensorflow as tf\n",
    "\n",
    "# TODO: Convert the following to TensorFlow:\n",
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = tf.subtract(tf.div(x,y),tf.constant(1))\n",
    "\n",
    "# TODO: Print z from a session\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Summary\n",
    "* Ran operations in tf.session.\n",
    "* Created a constant tensor with tf.constant().\n",
    "* Used tf.placeholder() and feed_dict to get input.\n",
    "* Applied the tf.add(), tf.subtract(), tf.multiply(), and tf.divide() functions using numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Supervised Classification - logistic classifier (aka. linear classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$WX+b=y$$ \n",
    "y(score) --> y(prob) by using softmax function. \n",
    "y(score) also called logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Weights and Bias in TensorFlow, using  tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable/read:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Variable Initialization\n",
    "x = tf.Variable(5)\n",
    "init = tf.global_variables_initializer()  #  initialize all TensorFlow variables from the graph.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initializing the weights with random numbers from a normal distribution (is a good practice)\n",
    "# no need to randomize the bias\n",
    "# tf.truncated_normal()\n",
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "# no need to randomize the bias. Let's use the simplest solution, setting the bias to 0\n",
    "n_labels = 5\n",
    "bias = tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Linear Classifier Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-19-dc6c17ef0341>:86: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 80, in <module>\n    logits = linear(features, w, b)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 35, in linear\n    return tf.add(tf.matmul(input, w), b)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1827, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2392, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dc6c17ef0341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m     _, l = session.run(\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         feed_dict={features: train_features, labels: train_labels})\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 80, in <module>\n    logits = linear(features, w, b)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 35, in linear\n    return tf.add(tf.matmul(input, w), b)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1827, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2392, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n"
     ]
    }
   ],
   "source": [
    "# Quiz Solution\n",
    "# Note: You can't run code in this tab\n",
    "import tensorflow as tf\n",
    "\n",
    "def weights(n_features, n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow weights\n",
    "    :param n_features: Number of features\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow weights\n",
    "    \"\"\"\n",
    "    # TODO: Return weights\n",
    "    return tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "\n",
    "def biases(n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow bias\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow bias\n",
    "    \"\"\"\n",
    "    # TODO: Return biases\n",
    "    return tf.Variable(tf.zeros(n_labels))\n",
    "\n",
    "\n",
    "def linear(input, w, b):\n",
    "    \"\"\"\n",
    "    Return linear function in TensorFlow\n",
    "    :param input: TensorFlow input\n",
    "    :param w: TensorFlow weights\n",
    "    :param b: TensorFlow biases\n",
    "    :return: TensorFlow linear function\n",
    "    \"\"\"\n",
    "    # TODO: Linear Function (xW + b)\n",
    "    return tf.add(tf.matmul(input, w), b)\n",
    "\n",
    "import tensorflow as tf\n",
    "# Sandbox Solution\n",
    "# Note: You can't run code in this tab\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#from quiz import weights, biases, linear\n",
    "\n",
    "\n",
    "def mnist_features_labels(n_labels):\n",
    "    \"\"\"\n",
    "    Gets the first <n> labels from the MNIST dataset\n",
    "    :param n_labels: Number of labels to use\n",
    "    :return: Tuple of feature list and label list\n",
    "    \"\"\"\n",
    "    mnist_features = []\n",
    "    mnist_labels = []\n",
    "\n",
    "    mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "    # In order to make quizzes run faster, we're only looking at 10000 images\n",
    "    for mnist_feature, mnist_label in zip(*mnist.train.next_batch(10000)):\n",
    "\n",
    "        # Add features and labels if it's for the first <n>th labels\n",
    "        if mnist_label[:n_labels].any():\n",
    "            mnist_features.append(mnist_feature)\n",
    "            mnist_labels.append(mnist_label[:n_labels])\n",
    "\n",
    "    return mnist_features, mnist_labels\n",
    "\n",
    "\n",
    "# Number of features (28*28 image is 784 features)\n",
    "n_features = 784\n",
    "# Number of labels\n",
    "n_labels = 3\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# Weights and Biases\n",
    "w = weights(n_features, n_labels)\n",
    "b = biases(n_labels)\n",
    "\n",
    "# Linear Function xW + b\n",
    "logits = linear(features, w, b)\n",
    "\n",
    "# Training data\n",
    "train_features, train_labels = mnist_features_labels(n_labels)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "\n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Cross entropy\n",
    "    # This quantifies how far off the predictions were.\n",
    "    # You'll learn more about this in future lessons.\n",
    "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "    # Training loss\n",
    "    # You'll learn more about this in future lessons.\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # Rate at which the weights are changed\n",
    "    # You'll learn more about this in future lessons.\n",
    "    learning_rate = 0.08\n",
    "\n",
    "    # Gradient Descent\n",
    "    # This is the method used to train the model\n",
    "    # You'll learn more about this in future lessons.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Run optimizer and get loss\n",
    "    _, l = session.run(\n",
    "        [optimizer, loss],\n",
    "        feed_dict={features: train_features, labels: train_labels})\n",
    "\n",
    "# Print loss\n",
    "print('Loss: {}'.format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### softmax quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8360188   0.11314284  0.05083836]\n",
      "[[ 0.09003057  0.00242826  0.01587624  0.33333333]\n",
      " [ 0.24472847  0.01794253  0.11731043  0.33333333]\n",
      " [ 0.66524096  0.97962921  0.86681333  0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# logits is a one-dimensional array\n",
    "logits = [3.0, 1.0, 0.2]\n",
    "print(softmax(logits))\n",
    "\n",
    "# logits is a two-dimensional array\n",
    "logits = np.array([\n",
    "    [1, 2, 3, 6],\n",
    "    [2, 4, 5, 6],\n",
    "    [3, 8, 7, 6]])\n",
    "\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow Softmax quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09003057  0.00242826  0.01587624  0.33333334]\n",
      " [ 0.24472848  0.01794253  0.11731043  0.33333334]\n",
      " [ 0.66524094  0.97962922  0.86681336  0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# one-dimension\n",
    "#logit_data = [2.0, 1.0, 0.1]\n",
    "# logits is a two-dimensional array\n",
    "logit_data = np.array([\n",
    "    [1, 2, 3, 6],\n",
    "    [2, 4, 5, 6],\n",
    "    [3, 8, 7, 6]])\n",
    "\n",
    "logits = tf.placeholder(tf.float32)\n",
    "softmax = tf.nn.softmax(logits,dim=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-Hot Encoding : [1.0, 0, 0, 0 ..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross Entropy: compare prediction vector (prob. vector: S(y)=softmax(y)) with one-hot encoding vector (L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### $$D(S,L) = -\\sum_{i} L_i log(S_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Multinomial logistic classification: $$D(S(WX+b), L)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Multinomial logistic classification quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356675\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "# ToDo: Print cross entropy from session\n",
    "#  tf.reduce_sum() function takes an array of numbers and sums them together\n",
    "cross_entropy = -tf.reduce_sum(tf.mul(one_hot, tf.log(softmax)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cross_entropy, feed_dict={softmax: softmax_data, one_hot: one_hot_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loss (average cross entropy across data set)\n",
    "$$L = \\frac{1}{N}\\sum_{i}D(S(WX_i+b),L_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Normalized Inputs and Initial Weights (for numerial stability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### zero mean: $$X_i = 0$$\n",
    "### equal variance: $$\\sigma (X_i) = \\sigma (X_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### input normalized as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if dealing with images [0..255] \n",
    "# (R-128)/128, (G-128)/128, (B-128)/128\n",
    "# already , zero mean, unit variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### weight initialized as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# zero mean , equal variance, Guassian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimization\n",
    "### $$W \\leftarrow W- \\alpha \\Delta_{W} L$$\n",
    "### $$b \\leftarrow b- \\alpha \\Delta_{b} L$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Momentum: change update from $$- \\alpha \\Delta L(w1,w2)$$ to $$- \\alpha M(w1,w2)$$\n",
    "where\n",
    "$$M \\leftarrow 0.9M + \\Delta L$$\n",
    "and M is the average of previous update direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Learning rate decay: $\\alpha$ becomes smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SGD 'hyerparameters'\n",
    "* initial learning rate\n",
    "* learning rate decay\n",
    "* momentum\n",
    "* batch size\n",
    "* weight initializatiogradn\n",
    "\n",
    "other approaches usch as Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Mini-batching quiz (* if run out of GPU mememory, try to reduce value in min-batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Test Accuracy: 0.07589999586343765\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from helper import batches\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# TODO: Set batch size\n",
    "batch_size = 128\n",
    "assert batch_size is not None, 'You must set the batch size'\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # TODO: Train optimizer on all batches\n",
    "    for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n",
    "        sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Epochs\n",
    "An epoch is a single forward and backward pass of the whole dataset. This is used to increase the accuracy of the model without requiring more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0    - Cost: 12.5     Valid Accuracy: 0.121\n",
      "Epoch: 1    - Cost: 11.4     Valid Accuracy: 0.139\n",
      "Epoch: 2    - Cost: 10.5     Valid Accuracy: 0.158\n",
      "Epoch: 3    - Cost: 9.79     Valid Accuracy: 0.177\n",
      "Epoch: 4    - Cost: 9.22     Valid Accuracy: 0.195\n",
      "Epoch: 5    - Cost: 8.73     Valid Accuracy: 0.211\n",
      "Epoch: 6    - Cost: 8.3      Valid Accuracy: 0.227\n",
      "Epoch: 7    - Cost: 7.9      Valid Accuracy: 0.241\n",
      "Epoch: 8    - Cost: 7.54     Valid Accuracy: 0.257\n",
      "Epoch: 9    - Cost: 7.21     Valid Accuracy: 0.272\n",
      "Test Accuracy: 0.2565999925136566\n"
     ]
    }
   ],
   "source": [
    "# example - 10 epochs\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from helper import batches  # Helper function created in Mini-batching section\n",
    "\n",
    "\n",
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "\n",
    "train_batches = batches(batch_size, train_features, train_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "tmp  = mnist.train.labels[0]\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson 7 - Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ReLU (Rectified Linear Units)\n",
    "tf.nn.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hidden Layer with ReLU activation function\n",
    "hidden_layer = tf.add(tf.matmul(features, hidden_weights), hidden_biases)\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "\n",
    "output = tf.add(tf.matmul(hidden_layer, output_weights), output_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2-Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow  ReLU Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-903963cf2b28>:34: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[  5.11000013   8.44000053]\n",
      " [  0.           0.        ]\n",
      " [ 24.01000023  38.24000168]]\n"
     ]
    }
   ],
   "source": [
    "# Quiz Solution\n",
    "# Note: You can't run code in this tab\n",
    "import tensorflow as tf\n",
    "\n",
    "output = None\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(sess.run(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Chain Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "(?, 28, 28, 1)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Epoch: 0001 cost= 31.222970963\n",
      "Epoch: 0002 cost= 23.596107483\n",
      "Epoch: 0003 cost= 26.079868317\n",
      "Epoch: 0004 cost= 15.320896149\n",
      "Epoch: 0005 cost= 16.770378113\n",
      "Epoch: 0006 cost= 13.724834442\n",
      "Epoch: 0007 cost= 10.041910172\n",
      "Epoch: 0008 cost= 12.290496826\n",
      "Epoch: 0009 cost= 12.547527313\n",
      "Epoch: 0010 cost= 10.923553467\n",
      "Epoch: 0011 cost= 10.887722969\n",
      "Epoch: 0012 cost= 12.834579468\n",
      "Epoch: 0013 cost= 7.874982834\n",
      "Epoch: 0014 cost= 10.116508484\n",
      "Epoch: 0015 cost= 3.749085665\n",
      "Epoch: 0016 cost= 13.790746689\n",
      "Epoch: 0017 cost= 7.065402031\n",
      "Epoch: 0018 cost= 7.294026375\n",
      "Epoch: 0019 cost= 5.354338646\n",
      "Epoch: 0020 cost= 4.751398087\n",
      "Optimization Finished!\n",
      "Accuracy: 0.820312\n"
     ]
    }
   ],
   "source": [
    "# example: multilayer perceptron\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "n_hidden_layer = 256 # layer number of features\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "x_flat = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(c))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    # Decrease test_size if you don't have enough memory\n",
    "    test_size = 256\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images[:test_size], y: mnist.test.labels[:test_size]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save and Restore TensorFlow Models\n",
    "using  tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[-0.22581583  0.97730374 -0.15746832]\n",
      " [-0.52505225 -1.2466743  -0.55889887]]\n",
      "Bias:\n",
      "[-0.70041877  0.16105421 -0.50394255]\n"
     ]
    }
   ],
   "source": [
    "# Saving Variables example\n",
    "import tensorflow as tf\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name=\"weights\")\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name=\"bias\")\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight:\n",
      "[[-0.22581583  0.97730374 -0.15746832]\n",
      " [-0.52505225 -1.2466743  -0.55889887]]\n",
      "Bias:\n",
      "[-0.70041877  0.16105421 -0.50394255]\n"
     ]
    }
   ],
   "source": [
    "# Loading Variables example\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name=\"weights\")\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name=\"bias\")\n",
    "\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Remove previous Tensors and Operations\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]), name=\"weights\")\n",
    "bias = tf.Variable(tf.random_normal([n_classes]), name=\"bias\")\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy: 0.11079999804496765\n",
      "Epoch 10  - Validation Accuracy: 0.26080000400543213\n",
      "Epoch 20  - Validation Accuracy: 0.4131999909877777\n",
      "Epoch 30  - Validation Accuracy: 0.5125999450683594\n",
      "Epoch 40  - Validation Accuracy: 0.5781998634338379\n",
      "Epoch 50  - Validation Accuracy: 0.6177998781204224\n",
      "Epoch 60  - Validation Accuracy: 0.6519998908042908\n",
      "Epoch 70  - Validation Accuracy: 0.681399941444397\n",
      "Epoch 80  - Validation Accuracy: 0.6997998952865601\n",
      "Epoch 90  - Validation Accuracy: 0.7171998620033264\n",
      "Trained Model Saved.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "save_file = './train_model.ckpt'\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    features: mnist.validation.images,\n",
    "                    labels: mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    print('Trained Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No variables to save",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0f53fb3209d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./train_model.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m784\u001b[0m  \u001b[0;31m# MNIST data input (img shape: 28*28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_step_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_step_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1070\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m       self.saver_def = self._builder.build(\n",
      "\u001b[0;31mValueError\u001b[0m: No variables to save"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_file = './train_model.ckpt'\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]), name=\"weights\")\n",
    "bias = tf.Variable(tf.random_normal([n_classes]), name=\"bias\")\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "\"\"\"\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\"\"\"\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.variables.Variable'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3596cd4d35d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(type(weights))\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: weights_0:0\n",
      "Save Bias: bias_0:0\n",
      "Load Weights: weights_0:0\n",
      "Load Bias: bias_0:0\n",
      "Loaded Weights and Bias successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = './model_new3.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "save_file = './model_new3.ckpt'\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - No Error\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "print('Loaded Weights and Bias successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Regularization\n",
    "* early termination\n",
    "* L2 regularization: $L' = L + \\beta \\frac{1}{2}\\left \\| W \\right \\|_{2}^{2}$\n",
    "* Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Dropout Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-8f016062c4ac>:34: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[  6.57999945   8.45999908]\n",
      " [  0.82600003   1.59000015]\n",
      " [  4.72000027  28.3200016 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model with Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print logits from a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(sess.run(logits, feed_dict={keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8 - Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translation invariance - weight sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"SAME\" padding equation:\n",
    "out_height = ceil(float(in_height) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"VALID\" padding equation:\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv layer dimension : calculate the number of neurons of output layer after conv\n",
    "\n",
    "Given:\n",
    "\n",
    "* our input layer has a width of W and a height of H\n",
    "* our convolutional layer has a filter size F\n",
    "* we have a stride of S\n",
    "* a padding of P\n",
    "* and the number of filters K,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following formula gives us the width of the next layer: W_out = (Wâˆ’F+2P)/S+1.\n",
    "\n",
    "The output height would be H_out = (H-F+2P)/S + 1.\n",
    "\n",
    "And the output depth would be equal to the number of filters D_out = K.\n",
    "\n",
    "The output volume would be W_out X H_out X D_out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convoultion output\n",
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
    "filter_bias = tf.Variable(tf.zeros(20))\n",
    "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
    "padding = 'SAME'\n",
    "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow \"same\" and \"valid\" padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAME Padding, the output height and width are computed as:\n",
    "\n",
    "out_height = ceil(float(in_height) / float(strides[1]))\n",
    "\n",
    "out_width = ceil(float(in_width) / float(strides[2]))\n",
    "\n",
    "# VALID Padding, the output height and width are computed as:\n",
    "\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides1))\n",
    "\n",
    "out_width = ceil(float(in_width - filter_width + 1) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Convolution Layer\n",
    "using tf.nn.conv2d() and tf.nn.bias_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN in TensorFlow\n",
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Convnet-ology\n",
    "* pooling - decrease the size of the output and prevent overfitting\n",
    "    * max pooling\n",
    "    * average pooling\n",
    "* 1x1 convolution\n",
    "* inception model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-10c2f80c2844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Apply Max Pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m conv_layer = tf.nn.max_pool(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weight' is not defined"
     ]
    }
   ],
   "source": [
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Network in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "Epoch  1, Batch   1 - Loss: 52895.3438 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch   2 - Loss: 40555.0820 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch   3 - Loss: 30850.3145 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch   4 - Loss: 26616.5449 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch   5 - Loss: 25695.7500 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch   6 - Loss: 25088.1758 Validation Accuracy: 0.187500\n",
      "Epoch  1, Batch   7 - Loss: 25009.5508 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch   8 - Loss: 21512.7324 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch   9 - Loss: 19807.7188 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  10 - Loss: 20735.6602 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  11 - Loss: 17088.7168 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  12 - Loss: 17257.2676 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  13 - Loss: 16424.7891 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  14 - Loss: 17615.4453 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  15 - Loss: 19296.3848 Validation Accuracy: 0.257812\n",
      "Epoch  1, Batch  16 - Loss: 16935.4785 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  17 - Loss: 14864.4326 Validation Accuracy: 0.273438\n",
      "Epoch  1, Batch  18 - Loss: 18105.7422 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  19 - Loss: 13303.1465 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  20 - Loss: 13528.0020 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  21 - Loss: 14121.4922 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  22 - Loss: 15418.5117 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  23 - Loss: 14909.8086 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  24 - Loss: 14049.0146 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  25 - Loss: 13817.0020 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  26 - Loss: 15893.8223 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  27 - Loss: 13780.1934 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  28 - Loss: 10931.5996 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  29 - Loss: 13458.2578 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  30 - Loss: 13943.5859 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  31 - Loss: 13042.2500 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  32 - Loss:  9177.5273 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  33 - Loss:  9641.4854 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  34 - Loss: 12173.9297 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  35 - Loss: 11279.1074 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  36 - Loss: 11343.8984 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  37 - Loss:  7343.1968 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  38 - Loss:  9762.4561 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  39 - Loss:  9317.5127 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  40 - Loss:  8835.6270 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  41 - Loss:  9021.4033 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  42 - Loss:  7598.8037 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  43 - Loss:  8036.8286 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  44 - Loss:  8526.4062 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  45 - Loss: 10805.4102 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  46 - Loss:  7280.5527 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  47 - Loss:  5575.8721 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  48 - Loss:  6960.9331 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  49 - Loss:  9728.5137 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  50 - Loss:  5939.1748 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  51 - Loss:  6216.6689 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  52 - Loss:  8381.4346 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  53 - Loss:  6185.0093 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  54 - Loss:  6004.4312 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  55 - Loss:  7092.4912 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  56 - Loss:  7616.0503 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  57 - Loss:  8515.5205 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  58 - Loss:  8356.7031 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  59 - Loss:  8882.1387 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  60 - Loss:  9961.0742 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  61 - Loss:  7470.6172 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  62 - Loss:  5570.1904 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  63 - Loss:  9718.4707 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  64 - Loss:  8952.1211 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  65 - Loss:  8184.6235 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  66 - Loss:  6063.1191 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  67 - Loss:  6461.8755 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  68 - Loss:  7789.4053 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  69 - Loss:  6957.3765 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  70 - Loss:  7046.5420 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  71 - Loss:  8581.4639 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  72 - Loss:  6760.2832 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  73 - Loss:  7811.6196 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  74 - Loss:  7514.0425 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  75 - Loss:  8580.7891 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  76 - Loss:  8376.9219 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  77 - Loss:  7603.3926 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  78 - Loss:  5854.3896 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  79 - Loss:  5433.8574 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  80 - Loss:  4981.7051 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  81 - Loss:  6474.3799 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  82 - Loss:  6195.6152 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch  83 - Loss:  5993.6787 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch  84 - Loss:  6878.2681 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  85 - Loss:  8443.6240 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  86 - Loss:  6100.3682 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch  87 - Loss:  6292.8198 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch  88 - Loss:  4719.9629 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch  89 - Loss:  4708.9897 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  90 - Loss:  4146.4072 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  91 - Loss:  5220.5288 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch  92 - Loss:  5345.9155 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch  93 - Loss:  6130.9395 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch  94 - Loss:  6683.4922 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch  95 - Loss:  6817.4990 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch  96 - Loss:  6220.5630 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch  97 - Loss:  4850.4390 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch  98 - Loss:  6037.4980 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch  99 - Loss:  6082.3525 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 100 - Loss:  6183.7729 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 101 - Loss:  3972.1240 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 102 - Loss:  3684.5356 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 103 - Loss:  4304.8193 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 104 - Loss:  3935.8928 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 105 - Loss:  5325.3311 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 106 - Loss:  3792.2065 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 107 - Loss:  4547.5649 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 108 - Loss:  4349.6650 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 109 - Loss:  4665.8882 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 110 - Loss:  4148.5273 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 111 - Loss:  6476.8784 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 112 - Loss:  4727.6938 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 113 - Loss:  3520.0991 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 114 - Loss:  4186.9775 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 115 - Loss:  2951.3770 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 116 - Loss:  4244.3330 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 117 - Loss:  4984.8398 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 118 - Loss:  6145.9419 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 119 - Loss:  5042.0103 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 120 - Loss:  4637.7168 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 121 - Loss:  2824.2749 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 122 - Loss:  4936.7671 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 123 - Loss:  4468.3799 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 124 - Loss:  3461.8521 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 125 - Loss:  4688.9009 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 126 - Loss:  3838.8301 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 127 - Loss:  3484.9998 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 128 - Loss:  3953.8887 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 129 - Loss:  5289.7891 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 130 - Loss:  4260.4570 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 131 - Loss:  3784.4470 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 132 - Loss:  2596.1089 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 133 - Loss:  2595.8428 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 134 - Loss:  6039.8179 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 135 - Loss:  5395.5674 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 136 - Loss:  2916.5320 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 137 - Loss:  4910.1841 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 138 - Loss:  5112.2510 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 139 - Loss:  4228.0420 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 140 - Loss:  3816.9375 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 141 - Loss:  2942.9297 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 142 - Loss:  5229.1523 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 143 - Loss:  3184.4487 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 144 - Loss:  2882.2793 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 145 - Loss:  3861.5312 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 146 - Loss:  3798.8176 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 147 - Loss:  3494.7173 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 148 - Loss:  4334.0498 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 149 - Loss:  3074.3955 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 150 - Loss:  3088.6797 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 151 - Loss:  4114.1533 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 152 - Loss:  3647.8728 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 153 - Loss:  5635.5879 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 154 - Loss:  3293.7925 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 155 - Loss:  3794.1360 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 156 - Loss:  2534.4451 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 157 - Loss:  1924.1282 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 158 - Loss:  4151.7622 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 159 - Loss:  4635.2173 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 160 - Loss:  2843.8474 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 161 - Loss:  2663.9800 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 162 - Loss:  2387.4414 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 163 - Loss:  3208.9717 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 164 - Loss:  2714.0117 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 165 - Loss:  1992.0015 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 166 - Loss:  2411.0764 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 167 - Loss:  2772.4761 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 168 - Loss:  3421.7004 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 169 - Loss:  3329.0610 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 170 - Loss:  3198.3892 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 171 - Loss:  2840.8030 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 172 - Loss:  3644.5386 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 173 - Loss:  3412.6675 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 174 - Loss:  4050.4568 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 175 - Loss:  2741.4004 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 176 - Loss:  3315.6941 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 177 - Loss:  2678.3428 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 178 - Loss:  2652.2168 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 179 - Loss:  3709.6240 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 180 - Loss:  1471.7693 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 181 - Loss:  2629.4189 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 182 - Loss:  2910.2119 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 183 - Loss:  3564.4392 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 184 - Loss:  2679.4644 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 185 - Loss:  4142.0767 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 186 - Loss:  2991.5828 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 187 - Loss:  2605.5642 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 188 - Loss:  3413.2778 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 189 - Loss:  3760.8232 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 190 - Loss:  3182.6279 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 191 - Loss:  3470.1350 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 192 - Loss:  2698.3032 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 193 - Loss:  2305.0825 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 194 - Loss:  3089.4028 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 195 - Loss:  3821.9766 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 196 - Loss:  3411.4294 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 197 - Loss:  3160.8003 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 198 - Loss:  2239.8010 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 199 - Loss:  3530.3276 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 200 - Loss:  3493.1301 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 201 - Loss:  2964.3286 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 202 - Loss:  3092.1982 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 203 - Loss:  3664.4675 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 204 - Loss:  3112.8184 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 205 - Loss:  3636.2139 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 206 - Loss:  4478.8936 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 207 - Loss:  2827.8799 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 208 - Loss:  2308.1807 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 209 - Loss:  3396.4932 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 210 - Loss:  2618.9487 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 211 - Loss:  2809.4551 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 212 - Loss:  4109.4541 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 213 - Loss:  3614.5864 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 214 - Loss:  3732.8823 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 215 - Loss:  4482.4551 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 216 - Loss:  2155.0991 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 217 - Loss:  1798.1265 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 218 - Loss:  2821.4761 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 219 - Loss:  2551.3599 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 220 - Loss:  2623.8882 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 221 - Loss:  2839.7563 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 222 - Loss:  2894.8340 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 223 - Loss:  2650.2178 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 224 - Loss:  1929.1151 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 225 - Loss:  2047.6455 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 226 - Loss:  1610.9402 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 227 - Loss:  2663.4233 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 228 - Loss:  2711.2095 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 229 - Loss:  1997.4628 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 230 - Loss:  2804.6035 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 231 - Loss:  3084.6318 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 232 - Loss:  2919.4773 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 233 - Loss:  3438.4268 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 234 - Loss:  3264.2380 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 235 - Loss:  2115.9971 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 236 - Loss:  2451.3550 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 237 - Loss:  2827.8208 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 238 - Loss:  2741.2339 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 239 - Loss:  2226.2373 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 240 - Loss:  2957.7634 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 241 - Loss:  1230.3239 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 242 - Loss:  2625.9927 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 243 - Loss:  2329.6836 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 244 - Loss:  2233.5093 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 245 - Loss:  1552.3806 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 246 - Loss:  2568.7681 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 247 - Loss:  2266.8960 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 248 - Loss:  1786.4509 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 249 - Loss:  2682.5508 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 250 - Loss:  1708.2615 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 251 - Loss:  2518.4966 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 252 - Loss:  1822.5747 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 253 - Loss:  3263.0476 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 254 - Loss:  2487.2205 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 255 - Loss:  2239.6392 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 256 - Loss:  1731.9799 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 257 - Loss:  2705.9453 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 258 - Loss:  1686.9178 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 259 - Loss:  2219.2710 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 260 - Loss:  2932.6418 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 261 - Loss:  2043.5533 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 262 - Loss:  1532.0619 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 263 - Loss:  3835.7253 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 264 - Loss:  2692.5015 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 265 - Loss:  1885.5110 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 266 - Loss:  2803.2341 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 267 - Loss:  1567.2576 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 268 - Loss:  2356.1733 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 269 - Loss:  3594.7195 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 270 - Loss:  2115.9604 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 271 - Loss:  2411.2383 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 272 - Loss:  2835.2837 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 273 - Loss:  3684.1030 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 274 - Loss:  2327.5215 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 275 - Loss:  2208.2864 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 276 - Loss:  2633.1958 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 277 - Loss:  1355.5591 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 278 - Loss:  2616.4941 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 279 - Loss:  2532.9519 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 280 - Loss:  2044.1951 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 281 - Loss:  1745.8025 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 282 - Loss:  2377.0999 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 283 - Loss:  1680.1388 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 284 - Loss:  2633.0376 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 285 - Loss:  3150.1367 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 286 - Loss:  2345.7773 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 287 - Loss:  1676.8260 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 288 - Loss:  2026.5090 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 289 - Loss:  1737.8442 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 290 - Loss:  2393.2163 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 291 - Loss:  2815.7212 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 292 - Loss:  3564.7080 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 293 - Loss:  2401.6599 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 294 - Loss:  2194.0413 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 295 - Loss:  2213.0723 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 296 - Loss:  2529.9500 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 297 - Loss:  3065.6519 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 298 - Loss:  1985.1169 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 299 - Loss:  1922.9150 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 300 - Loss:  1121.0253 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 301 - Loss:  2087.3579 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 302 - Loss:  2044.8158 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 303 - Loss:  1706.0714 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 304 - Loss:  2344.1792 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 305 - Loss:  1886.8462 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 306 - Loss:  2285.7834 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 307 - Loss:  2945.8521 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 308 - Loss:  1889.8771 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 309 - Loss:  1777.3015 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 310 - Loss:  1609.7407 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 311 - Loss:  2287.4763 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 312 - Loss:  1592.9045 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 313 - Loss:  1821.9948 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 314 - Loss:  2240.5674 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 315 - Loss:  1465.9088 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 316 - Loss:  2690.5874 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 317 - Loss:  2516.3955 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 318 - Loss:  1546.0427 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 319 - Loss:  2177.7402 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 320 - Loss:  2121.4941 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 321 - Loss:  1979.1573 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 322 - Loss:  2277.9492 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 323 - Loss:  2468.9199 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 324 - Loss:  2663.5054 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 325 - Loss:  1470.3000 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 326 - Loss:  2298.9622 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 327 - Loss:  1328.7219 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 328 - Loss:  1409.0732 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 329 - Loss:  2090.4351 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 330 - Loss:  2001.7300 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 331 - Loss:  2461.1418 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 332 - Loss:  2175.4761 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 333 - Loss:  2261.7844 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 334 - Loss:  1892.9170 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 335 - Loss:  2003.5332 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 336 - Loss:  2712.3174 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 337 - Loss:  1566.5664 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 338 - Loss:  1652.2217 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 339 - Loss:  2018.7822 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 340 - Loss:  1355.8621 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 341 - Loss:  2339.3208 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 342 - Loss:  1243.8203 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 343 - Loss:  1447.2743 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 344 - Loss:  3478.2600 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 345 - Loss:  2417.3501 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 346 - Loss:  2592.0801 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 347 - Loss:  1062.6550 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 348 - Loss:  3126.6250 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 349 - Loss:  2788.7229 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 350 - Loss:  1566.0065 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 351 - Loss:  2181.6646 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 352 - Loss:  1072.4268 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 353 - Loss:  1690.8088 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 354 - Loss:  1739.6040 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 355 - Loss:  3230.4761 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 356 - Loss:  1679.5254 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 357 - Loss:  1869.4474 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 358 - Loss:  2806.4622 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 359 - Loss:  1947.4772 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 360 - Loss:   920.7568 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 361 - Loss:  2163.7783 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 362 - Loss:  1994.2130 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 363 - Loss:  1324.3389 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 364 - Loss:  1450.9070 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 365 - Loss:  1238.1024 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 366 - Loss:  1722.2039 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 367 - Loss:  1285.6421 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 368 - Loss:  1325.7190 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 369 - Loss:  3507.1775 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 370 - Loss:  1278.3140 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 371 - Loss:   939.6166 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 372 - Loss:  1202.6298 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 373 - Loss:  1475.0095 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 374 - Loss:  1322.9438 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 375 - Loss:  2521.6843 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 376 - Loss:  1631.4915 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 377 - Loss:  1464.5726 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 378 - Loss:  1084.4932 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 379 - Loss:  1247.4619 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 380 - Loss:  2252.4897 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 381 - Loss:  1742.9822 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 382 - Loss:  1760.8247 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 383 - Loss:  2029.4159 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 384 - Loss:  1902.6779 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 385 - Loss:  1537.1133 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 386 - Loss:  1732.5443 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 387 - Loss:  1836.1097 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 388 - Loss:  1762.5350 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 389 - Loss:  1840.1477 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 390 - Loss:  2144.6296 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 391 - Loss:  2957.3826 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 392 - Loss:  1031.5961 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 393 - Loss:  1269.8695 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 394 - Loss:  1475.5455 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 395 - Loss:  1458.6028 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 396 - Loss:   885.6778 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 397 - Loss:  1181.4257 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 398 - Loss:  1187.7428 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 399 - Loss:  1301.3391 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 400 - Loss:  1062.1318 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 401 - Loss:  1429.5433 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 402 - Loss:  1448.0182 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 403 - Loss:  1646.3329 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 404 - Loss:  1903.9877 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 405 - Loss:  1898.1482 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 406 - Loss:  1338.8254 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 407 - Loss:  1490.8115 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 408 - Loss:   967.1617 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 409 - Loss:  1941.3752 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 410 - Loss:  1484.0421 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 411 - Loss:  1844.9817 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 412 - Loss:  2459.6455 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 413 - Loss:   689.8519 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 414 - Loss:  1442.9189 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 415 - Loss:  1070.7109 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 416 - Loss:   593.3518 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 417 - Loss:   651.2222 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 418 - Loss:  1567.6799 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 419 - Loss:  1027.7571 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 420 - Loss:  1182.3912 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 421 - Loss:  1229.5896 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 422 - Loss:   610.8869 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 423 - Loss:   940.9813 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 424 - Loss:  1049.6174 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 425 - Loss:  2367.1855 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 426 - Loss:  2176.3428 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 427 - Loss:   786.0591 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 428 - Loss:  2065.1777 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 429 - Loss:   630.8024 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch   1 - Loss:  2162.7700 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch   2 - Loss:  1446.9691 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch   3 - Loss:  1826.4781 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch   4 - Loss:  1579.3486 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch   5 - Loss:  1466.1671 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch   6 - Loss:  1965.0896 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch   7 - Loss:  1086.1375 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch   8 - Loss:  1853.9611 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch   9 - Loss:  1155.4927 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  10 - Loss:  1796.3041 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  11 - Loss:  1702.4763 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  12 - Loss:  2155.0156 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  13 - Loss:  1513.8164 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  14 - Loss:  1519.3007 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  15 - Loss:  2376.7476 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  16 - Loss:  1331.8260 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  17 - Loss:  1398.0702 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  18 - Loss:  1774.6479 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  19 - Loss:   854.4945 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  20 - Loss:  1723.4250 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  21 - Loss:  1436.6034 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  22 - Loss:  1441.6527 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  23 - Loss:  1939.1393 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  24 - Loss:  1216.4822 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  25 - Loss:  1491.1145 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  26 - Loss:  1864.5518 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  27 - Loss:  1263.0742 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  28 - Loss:  1527.3286 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  29 - Loss:  1612.4958 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  30 - Loss:  1851.7998 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  31 - Loss:  1920.6084 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  32 - Loss:  1445.6100 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  33 - Loss:  1515.8984 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  34 - Loss:  1612.0273 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  35 - Loss:  1564.4882 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  36 - Loss:  2214.2815 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  37 - Loss:  1509.1377 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  38 - Loss:   974.2811 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  39 - Loss:  1575.5471 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  40 - Loss:   932.4367 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  41 - Loss:  1796.6692 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  42 - Loss:  1338.5562 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  43 - Loss:  1473.4048 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  44 - Loss:  1124.5581 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  45 - Loss:  1234.3767 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  46 - Loss:  1490.5529 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  47 - Loss:  1445.4601 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  48 - Loss:  1867.9161 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  49 - Loss:  2584.2319 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  50 - Loss:  1784.9135 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  51 - Loss:  1511.3079 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  52 - Loss:   997.1649 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  53 - Loss:  1526.8228 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  54 - Loss:  1243.4329 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  55 - Loss:  1746.0852 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  56 - Loss:  1812.3094 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch  57 - Loss:  1281.5625 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch  58 - Loss:  1518.3939 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch  59 - Loss:  1224.6177 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  60 - Loss:  1684.6992 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  61 - Loss:  1484.1259 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  62 - Loss:  1536.9764 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  63 - Loss:  1051.3943 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch  64 - Loss:  1498.3428 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  65 - Loss:  1016.9316 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  66 - Loss:  1871.4141 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  67 - Loss:  1457.6035 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  68 - Loss:  1471.3351 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch  69 - Loss:  1308.6160 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  70 - Loss:  1374.4534 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  71 - Loss:  1207.8644 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  72 - Loss:  1537.2847 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  73 - Loss:  1029.7313 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  74 - Loss:  1319.3253 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  75 - Loss:   991.1637 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  76 - Loss:  1449.8738 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  77 - Loss:  1562.4282 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  78 - Loss:   866.9049 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  79 - Loss:   999.1116 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  80 - Loss:  1496.1870 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  81 - Loss:  1114.4395 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  82 - Loss:  1056.8463 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  83 - Loss:  1425.6018 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  84 - Loss:  1613.5637 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  85 - Loss:  1317.6174 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  86 - Loss:  1609.8850 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  87 - Loss:  1418.4741 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  88 - Loss:  1590.1296 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  89 - Loss:  1343.4243 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  90 - Loss:  1373.3560 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch  91 - Loss:  2120.5737 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  92 - Loss:  1148.2358 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch  93 - Loss:  1696.2313 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch  94 - Loss:  1428.7965 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  95 - Loss:  1177.8302 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch  96 - Loss:  1332.0474 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch  97 - Loss:  1027.8813 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch  98 - Loss:  1883.2963 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch  99 - Loss:  1646.6002 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 100 - Loss:  1961.4302 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 101 - Loss:  1358.6357 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 102 - Loss:  1077.1406 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 103 - Loss:  1811.6566 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 104 - Loss:  1670.1152 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 105 - Loss:  1390.8259 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 106 - Loss:  1275.2905 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 107 - Loss:  1771.1224 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 108 - Loss:  1397.0031 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 109 - Loss:   801.3342 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 110 - Loss:   879.3853 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 111 - Loss:  1392.6548 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 112 - Loss:  1677.3154 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 113 - Loss:  1400.5927 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 114 - Loss:  1331.3639 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 115 - Loss:  1169.5909 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 116 - Loss:   803.3058 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 117 - Loss:  1942.3951 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 118 - Loss:  1222.7891 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 119 - Loss:   968.5513 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 120 - Loss:   903.7571 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 121 - Loss:  1101.2227 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 122 - Loss:  1496.5154 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 123 - Loss:  1695.5981 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 124 - Loss:  1626.2230 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 125 - Loss:   972.4874 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 126 - Loss:  1703.2753 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 127 - Loss:  1568.1056 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 128 - Loss:  1690.4771 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 129 - Loss:  1666.9155 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 130 - Loss:  1288.1250 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 131 - Loss:  1195.8710 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 132 - Loss:   804.2346 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 133 - Loss:   918.4437 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 134 - Loss:  1092.1273 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 135 - Loss:  1443.1582 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 136 - Loss:  1307.1138 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 137 - Loss:  1395.6942 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 138 - Loss:  1802.2208 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 139 - Loss:  1504.1514 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 140 - Loss:  1113.7273 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 141 - Loss:  1566.8811 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 142 - Loss:  1089.5247 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 143 - Loss:  1356.6194 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 144 - Loss:  1196.0376 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 145 - Loss:  1220.4751 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 146 - Loss:  1337.9503 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 147 - Loss:  1466.2788 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 148 - Loss:  1049.1963 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 149 - Loss:   819.6235 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 150 - Loss:  1824.6895 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 151 - Loss:   873.1840 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 152 - Loss:  1457.5264 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 153 - Loss:  1062.0415 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 154 - Loss:   963.2877 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 155 - Loss:  1351.2369 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 156 - Loss:  1491.9053 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 157 - Loss:  1171.4048 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 158 - Loss:  1486.6178 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 159 - Loss:  1418.4309 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 160 - Loss:  1249.7413 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 161 - Loss:   913.7931 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 162 - Loss:  1248.6265 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 163 - Loss:  1669.4395 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 164 - Loss:  1410.5300 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 165 - Loss:   986.5636 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 166 - Loss:  1392.3123 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 167 - Loss:  1166.5726 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 168 - Loss:  1213.8749 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 169 - Loss:  1229.4763 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 170 - Loss:  1741.5068 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 171 - Loss:  1246.3308 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 172 - Loss:   957.1289 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 173 - Loss:  1855.2146 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 174 - Loss:  1171.4695 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 175 - Loss:  1397.0427 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 176 - Loss:  1344.5232 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 177 - Loss:  1234.0333 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 178 - Loss:  1637.2964 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 179 - Loss:   817.2193 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 180 - Loss:  1399.3319 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 181 - Loss:  1537.6829 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 182 - Loss:   925.2007 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 183 - Loss:  1534.7356 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 184 - Loss:   898.7504 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 185 - Loss:  1156.6538 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 186 - Loss:   760.6060 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 187 - Loss:   641.7986 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 188 - Loss:  1113.2218 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 189 - Loss:  1213.6510 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 190 - Loss:  1353.0510 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 191 - Loss:  1240.2822 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 192 - Loss:  1286.9222 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 193 - Loss:  1318.2637 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 194 - Loss:   989.5873 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 195 - Loss:   814.2233 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 196 - Loss:  1697.4553 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 197 - Loss:  1195.0394 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 198 - Loss:  1121.2246 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 199 - Loss:  1165.2137 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 200 - Loss:  1193.5962 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 201 - Loss:  1784.8846 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 202 - Loss:  1005.9791 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 203 - Loss:   940.0793 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 204 - Loss:   910.3793 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 205 - Loss:  1202.7708 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 206 - Loss:  1195.4904 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 207 - Loss:  1893.3845 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 208 - Loss:  1323.4213 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 209 - Loss:  1112.7175 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 210 - Loss:  1511.3306 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 211 - Loss:  1348.4840 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 212 - Loss:  1279.6328 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 213 - Loss:  1582.9880 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 214 - Loss:  1115.5836 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 215 - Loss:  1707.0996 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 216 - Loss:  1018.5359 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 217 - Loss:  1519.1309 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 218 - Loss:  1333.6531 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 219 - Loss:  1039.6819 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 220 - Loss:  1380.9075 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 221 - Loss:  1170.0309 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 222 - Loss:  1963.0321 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 223 - Loss:  1342.7919 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 224 - Loss:  1287.0378 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 225 - Loss:  1069.8357 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 226 - Loss:  1396.8755 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 227 - Loss:   946.2078 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 228 - Loss:  1106.8594 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 229 - Loss:   864.4632 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 230 - Loss:   998.8275 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 231 - Loss:  1129.6295 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 232 - Loss:  1248.2253 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 233 - Loss:   785.1020 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 234 - Loss:   803.5378 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 235 - Loss:   960.9716 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 236 - Loss:  1374.7856 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 237 - Loss:   861.5090 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 238 - Loss:  1033.5708 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 239 - Loss:  1296.1407 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 240 - Loss:  1539.5920 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 241 - Loss:   996.4529 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 242 - Loss:  1261.0553 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 243 - Loss:  1566.1362 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 244 - Loss:  1137.1987 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 245 - Loss:  1111.5868 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 246 - Loss:  1897.0219 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 247 - Loss:  1011.5288 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 248 - Loss:   803.2952 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 249 - Loss:  1034.2780 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 250 - Loss:  1045.8955 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 251 - Loss:   782.6685 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 252 - Loss:  1466.9993 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 253 - Loss:  1079.8274 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 254 - Loss:  1497.1674 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 255 - Loss:  1437.6350 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 256 - Loss:  1148.0508 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 257 - Loss:  1089.5571 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 258 - Loss:  1025.4906 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 259 - Loss:  1185.3767 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 260 - Loss:  1075.5566 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 261 - Loss:   823.6707 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 262 - Loss:  1589.9790 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 263 - Loss:  1059.2054 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 264 - Loss:  2272.1997 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 265 - Loss:  1022.1689 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 266 - Loss:  1358.5798 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 267 - Loss:  1239.7020 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 268 - Loss:  1564.2308 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 269 - Loss:  1106.1678 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 270 - Loss:  1021.1127 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 271 - Loss:  1252.0663 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 272 - Loss:  1619.2983 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 273 - Loss:  1042.7676 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 274 - Loss:  1154.3613 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 275 - Loss:  1268.7411 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 276 - Loss:  1075.1887 Validation Accuracy: 0.816406\n",
      "Epoch  2, Batch 277 - Loss:  1133.4462 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 278 - Loss:  1081.2246 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 279 - Loss:   931.0596 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 280 - Loss:  1309.0991 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 281 - Loss:  2112.6580 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 282 - Loss:   715.4681 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 283 - Loss:   811.5273 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 284 - Loss:  1376.9841 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 285 - Loss:  1118.0001 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 286 - Loss:  1168.7939 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 287 - Loss:  1288.2745 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 288 - Loss:  1463.7471 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 289 - Loss:   761.5714 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 290 - Loss:  1624.4323 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 291 - Loss:   726.0879 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 292 - Loss:  1359.5044 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 293 - Loss:   677.8292 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 294 - Loss:  1651.7090 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 295 - Loss:   964.1666 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 296 - Loss:  1399.9409 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 297 - Loss:  1105.8774 Validation Accuracy: 0.785156\n",
      "Epoch  2, Batch 298 - Loss:  1086.1064 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 299 - Loss:  1177.7585 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 300 - Loss:  1226.1771 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 301 - Loss:  1309.7726 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 302 - Loss:  1565.7904 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 303 - Loss:   810.3027 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 304 - Loss:   709.2794 Validation Accuracy: 0.789062\n",
      "Epoch  2, Batch 305 - Loss:  1517.1372 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 306 - Loss:  1229.1432 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 307 - Loss:   969.4348 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 308 - Loss:  1300.7616 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 309 - Loss:  1646.2255 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 310 - Loss:  1307.7610 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 311 - Loss:  1052.9729 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 312 - Loss:   818.0920 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 313 - Loss:  1200.3101 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 314 - Loss:   800.4065 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 315 - Loss:  1114.8115 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 316 - Loss:  1105.2904 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 317 - Loss:  1095.7012 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 318 - Loss:   604.1485 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 319 - Loss:   837.1941 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 320 - Loss:  1259.6892 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 321 - Loss:   596.9483 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 322 - Loss:  1716.0283 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 323 - Loss:  1019.1208 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 324 - Loss:   976.6817 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 325 - Loss:   976.4500 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 326 - Loss:   998.3978 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 327 - Loss:  1085.5525 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 328 - Loss:  1034.6556 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 329 - Loss:  1177.5593 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 330 - Loss:  1182.4895 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 331 - Loss:  1050.4866 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 332 - Loss:   902.4490 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 333 - Loss:  1037.5073 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 334 - Loss:   884.6980 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 335 - Loss:   984.1657 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 336 - Loss:  1177.3441 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 337 - Loss:  1135.4941 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 338 - Loss:  1347.7791 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 339 - Loss:  1149.8558 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 340 - Loss:  1165.2332 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 341 - Loss:   594.3370 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 342 - Loss:  1026.8015 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 343 - Loss:   767.6699 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 344 - Loss:   841.1611 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 345 - Loss:  1188.6770 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 346 - Loss:  1110.6143 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 347 - Loss:  1274.6638 Validation Accuracy: 0.792969\n",
      "Epoch  2, Batch 348 - Loss:   807.8315 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 349 - Loss:   866.4572 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 350 - Loss:   971.4651 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 351 - Loss:  1380.4536 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 352 - Loss:  1096.2244 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 353 - Loss:   874.0654 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 354 - Loss:   978.0236 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 355 - Loss:  1048.6348 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 356 - Loss:  1033.1581 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 357 - Loss:   995.8163 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 358 - Loss:   974.4661 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 359 - Loss:  1042.3970 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 360 - Loss:   761.6614 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 361 - Loss:  1114.4897 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 362 - Loss:  1192.5569 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 363 - Loss:   697.2760 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 364 - Loss:   867.3563 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 365 - Loss:   926.9161 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 366 - Loss:   901.6317 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 367 - Loss:  1280.5134 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 368 - Loss:  1347.2815 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 369 - Loss:  1303.3433 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 370 - Loss:   943.9685 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 371 - Loss:  1796.8922 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 372 - Loss:   873.8618 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 373 - Loss:  1180.0508 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 374 - Loss:   849.1520 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 375 - Loss:   856.2055 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 376 - Loss:   921.9705 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 377 - Loss:   706.2504 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 378 - Loss:   685.8823 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 379 - Loss:  1004.8666 Validation Accuracy: 0.816406\n",
      "Epoch  2, Batch 380 - Loss:  1002.0585 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 381 - Loss:   951.6298 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 382 - Loss:  1385.0511 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 383 - Loss:  1128.6606 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 384 - Loss:   555.7219 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 385 - Loss:  1419.8861 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 386 - Loss:  1042.5789 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 387 - Loss:   898.9818 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 388 - Loss:  1050.1848 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 389 - Loss:   849.9211 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 390 - Loss:   594.3705 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 391 - Loss:   950.9214 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 392 - Loss:   886.5386 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 393 - Loss:  1102.5562 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 394 - Loss:   725.5377 Validation Accuracy: 0.796875\n",
      "Epoch  2, Batch 395 - Loss:   892.9197 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 396 - Loss:   881.5321 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 397 - Loss:   810.6165 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 398 - Loss:   847.5441 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 399 - Loss:  1602.9319 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 400 - Loss:   687.0961 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 401 - Loss:  1272.2275 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 402 - Loss:   943.6816 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 403 - Loss:  1143.8018 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 404 - Loss:   980.8931 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 405 - Loss:  1415.6545 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 406 - Loss:  1217.5146 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 407 - Loss:  1300.6995 Validation Accuracy: 0.800781\n",
      "Epoch  2, Batch 408 - Loss:   917.1763 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 409 - Loss:  1045.1510 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 410 - Loss:  1287.0044 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 411 - Loss:  1036.2264 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 412 - Loss:  1253.2411 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 413 - Loss:  1320.7310 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 414 - Loss:  1178.3804 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 415 - Loss:  1292.4807 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 416 - Loss:   785.6115 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 417 - Loss:   958.7704 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 418 - Loss:   855.7778 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 419 - Loss:  1200.5697 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 420 - Loss:   634.8574 Validation Accuracy: 0.804688\n",
      "Epoch  2, Batch 421 - Loss:   911.8520 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 422 - Loss:   757.1558 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 423 - Loss:   716.4187 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 424 - Loss:  1010.0751 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 425 - Loss:  1010.9353 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch 426 - Loss:   695.6285 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 427 - Loss:   804.0441 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 428 - Loss:   664.6816 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch 429 - Loss:  1052.9468 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch   1 - Loss:  1148.2891 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch   2 - Loss:   944.3275 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch   3 - Loss:  1096.6581 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch   4 - Loss:   862.0178 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch   5 - Loss:   694.6927 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch   6 - Loss:   647.1583 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch   7 - Loss:   933.2148 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch   8 - Loss:  1176.1453 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch   9 - Loss:   896.7604 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  10 - Loss:   958.2263 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch  11 - Loss:   700.1658 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch  12 - Loss:  1431.6018 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  13 - Loss:   821.1034 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  14 - Loss:   839.7569 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch  15 - Loss:   968.1772 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  16 - Loss:   519.4588 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  17 - Loss:   928.0738 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  18 - Loss:  1112.7068 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  19 - Loss:   643.5048 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  20 - Loss:   834.1714 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  21 - Loss:   657.2505 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  22 - Loss:   816.7590 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  23 - Loss:  1249.3676 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  24 - Loss:  1213.4688 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  25 - Loss:  1035.2869 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  26 - Loss:  1038.3325 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  27 - Loss:   981.8953 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  28 - Loss:  1031.4832 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  29 - Loss:   864.6290 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  30 - Loss:  1621.4049 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  31 - Loss:   898.6758 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  32 - Loss:  1144.6345 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  33 - Loss:  1327.8312 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  34 - Loss:   656.7994 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  35 - Loss:   803.9133 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  36 - Loss:  1100.0688 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  37 - Loss:  1318.3824 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  38 - Loss:   596.3975 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  39 - Loss:  1094.1827 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  40 - Loss:   593.0999 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  41 - Loss:  1042.7357 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  42 - Loss:  1038.1069 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  43 - Loss:   848.2748 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  44 - Loss:   533.0491 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  45 - Loss:   967.9724 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  46 - Loss:  1114.7455 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  47 - Loss:   898.1168 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  48 - Loss:   783.2522 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  49 - Loss:   884.6724 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  50 - Loss:  1066.3248 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  51 - Loss:  1019.9994 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  52 - Loss:  1090.1394 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch  53 - Loss:  1035.7966 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  54 - Loss:  1327.6556 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch  55 - Loss:  1028.4884 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  56 - Loss:  1272.9716 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch  57 - Loss:   659.2595 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  58 - Loss:   735.0983 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  59 - Loss:   958.6023 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch  60 - Loss:  1043.1981 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  61 - Loss:  1012.7352 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  62 - Loss:   705.2769 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch  63 - Loss:  1208.3503 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  64 - Loss:   448.1247 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  65 - Loss:  1256.6382 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  66 - Loss:   882.7573 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch  67 - Loss:  1078.9116 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  68 - Loss:   870.4319 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  69 - Loss:   958.8485 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  70 - Loss:   879.4825 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  71 - Loss:  1331.3615 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  72 - Loss:   625.0342 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  73 - Loss:   958.4155 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  74 - Loss:  1158.2334 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch  75 - Loss:  1267.1173 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  76 - Loss:   932.7288 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  77 - Loss:   722.0659 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  78 - Loss:   939.2122 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  79 - Loss:   800.8910 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch  80 - Loss:   842.4903 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch  81 - Loss:   904.8862 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  82 - Loss:   942.0001 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  83 - Loss:   787.0035 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  84 - Loss:   699.0964 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  85 - Loss:   855.6353 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  86 - Loss:  1156.0077 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  87 - Loss:   998.9730 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch  88 - Loss:  1157.6995 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  89 - Loss:   775.5284 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch  90 - Loss:   787.4248 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  91 - Loss:   813.0428 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  92 - Loss:   924.5135 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch  93 - Loss:   463.5804 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch  94 - Loss:  1101.3035 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch  95 - Loss:   631.3916 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch  96 - Loss:   861.4230 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch  97 - Loss:  1145.7030 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch  98 - Loss:   762.0999 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch  99 - Loss:   729.0767 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 100 - Loss:  1011.4248 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 101 - Loss:   998.9926 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 102 - Loss:   296.3185 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 103 - Loss:   626.8041 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 104 - Loss:  1067.0890 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 105 - Loss:  1081.2454 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 106 - Loss:   838.3644 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 107 - Loss:   946.1781 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 108 - Loss:   696.2688 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 109 - Loss:  1089.4069 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 110 - Loss:  1047.1598 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 111 - Loss:  1043.5267 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 112 - Loss:   690.6161 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 113 - Loss:  1072.4894 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 114 - Loss:  1220.9524 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 115 - Loss:   718.3256 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 116 - Loss:  1182.1085 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 117 - Loss:   739.1989 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 118 - Loss:   911.6048 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 119 - Loss:   778.5422 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 120 - Loss:   710.4081 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 121 - Loss:   758.0618 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 122 - Loss:   964.6286 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 123 - Loss:  1018.5262 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 124 - Loss:   635.9993 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 125 - Loss:  1309.0980 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 126 - Loss:   976.2683 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 127 - Loss:  1096.1919 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 128 - Loss:   546.3169 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 129 - Loss:   700.1341 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 130 - Loss:   668.5131 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 131 - Loss:  1128.6221 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 132 - Loss:   660.8621 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 133 - Loss:   624.4127 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 134 - Loss:  1180.6179 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 135 - Loss:   935.3021 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 136 - Loss:   985.5466 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 137 - Loss:   752.1735 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 138 - Loss:  1523.7107 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 139 - Loss:   960.6771 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 140 - Loss:   987.8542 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 141 - Loss:  1002.4946 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 142 - Loss:  1101.9312 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 143 - Loss:  1285.7522 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 144 - Loss:   673.6934 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 145 - Loss:  1065.3047 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 146 - Loss:   933.0314 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 147 - Loss:  1041.3406 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 148 - Loss:   724.2062 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 149 - Loss:   553.1884 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 150 - Loss:   891.2265 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 151 - Loss:  1083.2615 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 152 - Loss:  1032.2648 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 153 - Loss:   718.5495 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 154 - Loss:  1121.9443 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 155 - Loss:   679.9043 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 156 - Loss:   764.5980 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 157 - Loss:  1227.2534 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 158 - Loss:   732.5392 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 159 - Loss:   813.9414 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 160 - Loss:  1020.9035 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 161 - Loss:  1114.9131 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 162 - Loss:   606.6031 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 163 - Loss:   679.0774 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 164 - Loss:   957.2726 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 165 - Loss:   960.5698 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 166 - Loss:   932.5670 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 167 - Loss:   822.2466 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 168 - Loss:   950.7473 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 169 - Loss:   895.5665 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 170 - Loss:   784.9204 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 171 - Loss:   870.9581 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 172 - Loss:   703.7935 Validation Accuracy: 0.812500\n",
      "Epoch  3, Batch 173 - Loss:  1248.9663 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 174 - Loss:   824.3552 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 175 - Loss:   857.0452 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 176 - Loss:   951.1129 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 177 - Loss:   716.0319 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 178 - Loss:   680.7554 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 179 - Loss:   970.8425 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 180 - Loss:   630.9573 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 181 - Loss:   458.6371 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 182 - Loss:  1096.1702 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 183 - Loss:  1291.7236 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 184 - Loss:   535.4630 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 185 - Loss:   800.5525 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 186 - Loss:   914.5656 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 187 - Loss:  1014.1099 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 188 - Loss:   971.8507 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 189 - Loss:  1102.2686 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 190 - Loss:  1201.7915 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 191 - Loss:  1140.6831 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 192 - Loss:  1111.9913 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 193 - Loss:   752.7896 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 194 - Loss:   671.9747 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 195 - Loss:  1036.3162 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 196 - Loss:   626.9794 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 197 - Loss:  1074.5499 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 198 - Loss:  1039.7994 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 199 - Loss:   713.4460 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 200 - Loss:   784.0639 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 201 - Loss:   663.0975 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 202 - Loss:   560.8745 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 203 - Loss:   830.9102 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 204 - Loss:   763.6587 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 205 - Loss:   565.5767 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 206 - Loss:  1370.1501 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 207 - Loss:   425.8961 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 208 - Loss:  1026.5371 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 209 - Loss:  1067.5663 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 210 - Loss:   865.8621 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 211 - Loss:   431.6720 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 212 - Loss:  1119.2700 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 213 - Loss:  1251.2181 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 214 - Loss:   736.5778 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 215 - Loss:  1297.2732 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 216 - Loss:   676.6616 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 217 - Loss:   543.6713 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 218 - Loss:   809.6932 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 219 - Loss:   447.5022 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 220 - Loss:  1215.0947 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 221 - Loss:  1085.6069 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 222 - Loss:   648.5911 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 223 - Loss:   949.6450 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 224 - Loss:   456.7487 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 225 - Loss:  1268.5684 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 226 - Loss:   879.2675 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 227 - Loss:   470.7291 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 228 - Loss:  1056.6064 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 229 - Loss:   810.2797 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 230 - Loss:   912.7058 Validation Accuracy: 0.847656\n",
      "Epoch  3, Batch 231 - Loss:   900.2459 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 232 - Loss:   822.0793 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 233 - Loss:   802.4118 Validation Accuracy: 0.847656\n",
      "Epoch  3, Batch 234 - Loss:  1047.1344 Validation Accuracy: 0.847656\n",
      "Epoch  3, Batch 235 - Loss:   804.8763 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 236 - Loss:  1266.6703 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 237 - Loss:   641.5428 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 238 - Loss:   942.9238 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 239 - Loss:  1007.7414 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 240 - Loss:   889.9510 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 241 - Loss:   666.6021 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 242 - Loss:   874.9203 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 243 - Loss:   800.3172 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 244 - Loss:   643.0671 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 245 - Loss:   682.5148 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 246 - Loss:   652.5397 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 247 - Loss:   553.3029 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 248 - Loss:  1529.6687 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 249 - Loss:   802.1494 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 250 - Loss:   490.1000 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 251 - Loss:   815.7115 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 252 - Loss:  1092.1516 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 253 - Loss:   614.6831 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 254 - Loss:  1012.5793 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 255 - Loss:  1081.4941 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 256 - Loss:  1216.8838 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 257 - Loss:   761.9304 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 258 - Loss:   688.9346 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 259 - Loss:   837.1218 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 260 - Loss:   834.6323 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 261 - Loss:   497.3958 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 262 - Loss:   612.9524 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 263 - Loss:   734.2921 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 264 - Loss:   727.7245 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 265 - Loss:   662.8876 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 266 - Loss:  1181.1345 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 267 - Loss:   842.0674 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 268 - Loss:   824.2431 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 269 - Loss:   859.3723 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 270 - Loss:   714.3516 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 271 - Loss:   871.9392 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 272 - Loss:   849.8997 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 273 - Loss:  1020.0366 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 274 - Loss:   499.9737 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 275 - Loss:   713.7141 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 276 - Loss:   718.5051 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 277 - Loss:   806.0880 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 278 - Loss:   950.7631 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 279 - Loss:   604.7924 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 280 - Loss:   712.1936 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 281 - Loss:   989.2916 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 282 - Loss:   801.4993 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 283 - Loss:   810.2141 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 284 - Loss:   822.1339 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 285 - Loss:   674.8915 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 286 - Loss:  1019.9164 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 287 - Loss:  1043.3652 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 288 - Loss:  1215.6506 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 289 - Loss:   603.0068 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 290 - Loss:   651.8569 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 291 - Loss:   837.5008 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 292 - Loss:  1070.2196 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 293 - Loss:   815.6265 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 294 - Loss:   609.7239 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 295 - Loss:   866.2048 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 296 - Loss:   657.2947 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 297 - Loss:   852.2423 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 298 - Loss:   490.5128 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 299 - Loss:   644.2008 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 300 - Loss:  1301.2302 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 301 - Loss:   942.5771 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 302 - Loss:   739.9890 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 303 - Loss:  1056.8623 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 304 - Loss:   861.1691 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 305 - Loss:   772.2749 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 306 - Loss:   762.3800 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 307 - Loss:   884.1330 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 308 - Loss:   876.9871 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 309 - Loss:   872.8977 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 310 - Loss:   861.8098 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 311 - Loss:   830.8347 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 312 - Loss:   901.9074 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 313 - Loss:   715.0858 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 314 - Loss:   898.2169 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 315 - Loss:  1030.9960 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 316 - Loss:   368.2555 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 317 - Loss:   762.5349 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 318 - Loss:   816.0539 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 319 - Loss:   923.6288 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 320 - Loss:   792.0957 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 321 - Loss:   777.7289 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 322 - Loss:   823.1239 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 323 - Loss:   860.2674 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 324 - Loss:   732.1381 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 325 - Loss:  1054.9805 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 326 - Loss:   696.5215 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 327 - Loss:  1123.8727 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 328 - Loss:   903.0331 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 329 - Loss:   779.3634 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 330 - Loss:   779.0235 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 331 - Loss:   869.0629 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 332 - Loss:   796.3621 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 333 - Loss:   549.3892 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 334 - Loss:   664.6483 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 335 - Loss:  1025.3717 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 336 - Loss:   583.1872 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 337 - Loss:   493.1737 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 338 - Loss:   902.4557 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 339 - Loss:   833.9844 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 340 - Loss:   722.2663 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 341 - Loss:   677.3497 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 342 - Loss:  1053.2529 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 343 - Loss:   410.3812 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 344 - Loss:   447.1208 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 345 - Loss:   772.9712 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 346 - Loss:   741.9133 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 347 - Loss:   863.7156 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 348 - Loss:   789.3373 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 349 - Loss:   815.3087 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 350 - Loss:   998.4811 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 351 - Loss:   946.5292 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 352 - Loss:   634.7238 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 353 - Loss:   806.8871 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 354 - Loss:   507.1081 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 355 - Loss:   450.6200 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 356 - Loss:   832.6618 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 357 - Loss:  1091.1945 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 358 - Loss:   466.6913 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 359 - Loss:   719.8266 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 360 - Loss:   790.1334 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 361 - Loss:   713.9086 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 362 - Loss:   844.5911 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 363 - Loss:   757.6287 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 364 - Loss:  1148.9960 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 365 - Loss:  1145.5577 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 366 - Loss:   505.1789 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch 367 - Loss:   529.8428 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 368 - Loss:   713.2443 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 369 - Loss:   669.1321 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 370 - Loss:   528.3265 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 371 - Loss:   855.0470 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 372 - Loss:   691.6495 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 373 - Loss:   655.1315 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 374 - Loss:   598.4379 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 375 - Loss:   777.8808 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 376 - Loss:   462.8631 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 377 - Loss:   743.1604 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 378 - Loss:   898.1516 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 379 - Loss:   666.5313 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 380 - Loss:   746.1218 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 381 - Loss:   727.0543 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 382 - Loss:   703.7488 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 383 - Loss:   663.1992 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 384 - Loss:   670.4659 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 385 - Loss:   491.0737 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 386 - Loss:   817.8860 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 387 - Loss:   551.5859 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 388 - Loss:  1004.4967 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 389 - Loss:   960.8315 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 390 - Loss:   899.1811 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 391 - Loss:   722.3998 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 392 - Loss:   538.3599 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 393 - Loss:   674.1500 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 394 - Loss:   523.2018 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 395 - Loss:   703.6395 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 396 - Loss:   707.1770 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 397 - Loss:   743.1423 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 398 - Loss:   571.7628 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 399 - Loss:  1010.7670 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 400 - Loss:   437.4961 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 401 - Loss:   296.7475 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 402 - Loss:   741.8917 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 403 - Loss:   619.3440 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 404 - Loss:  1034.3239 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 405 - Loss:   917.2698 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 406 - Loss:   884.6799 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch 407 - Loss:   792.9946 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 408 - Loss:   583.4634 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 409 - Loss:   923.6723 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 410 - Loss:   614.6810 Validation Accuracy: 0.816406\n",
      "Epoch  3, Batch 411 - Loss:   867.0485 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 412 - Loss:   847.1078 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 413 - Loss:   910.8315 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 414 - Loss:   890.8447 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 415 - Loss:   430.9749 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 416 - Loss:   684.7732 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 417 - Loss:   666.9614 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 418 - Loss:   876.3199 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 419 - Loss:   880.6266 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 420 - Loss:   703.0735 Validation Accuracy: 0.828125\n",
      "Epoch  3, Batch 421 - Loss:   770.7444 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 422 - Loss:   550.3612 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 423 - Loss:   623.8085 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 424 - Loss:   722.4891 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 425 - Loss:  1126.5217 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 426 - Loss:  1032.8607 Validation Accuracy: 0.820312\n",
      "Epoch  3, Batch 427 - Loss:   690.5778 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 428 - Loss:   918.3424 Validation Accuracy: 0.824219\n",
      "Epoch  3, Batch 429 - Loss:   854.8604 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch   1 - Loss:   771.0511 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch   2 - Loss:   605.7225 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch   3 - Loss:   712.0793 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch   4 - Loss:   792.0599 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch   5 - Loss:   672.3146 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch   6 - Loss:  1022.7736 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch   7 - Loss:   898.7661 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch   8 - Loss:   899.4657 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch   9 - Loss:   505.9092 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch  10 - Loss:   459.9232 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch  11 - Loss:   579.5170 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch  12 - Loss:  1242.5033 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch  13 - Loss:   704.3176 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch  14 - Loss:   474.2873 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch  15 - Loss:  1018.4783 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch  16 - Loss:   877.7256 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch  17 - Loss:   822.4978 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  18 - Loss:   564.6090 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch  19 - Loss:   611.5737 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  20 - Loss:   847.9588 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  21 - Loss:   538.4045 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  22 - Loss:   527.9830 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  23 - Loss:   547.4773 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  24 - Loss:   626.7653 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  25 - Loss:   561.9966 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  26 - Loss:   950.8010 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  27 - Loss:  1016.0436 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  28 - Loss:   886.2855 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  29 - Loss:   548.5780 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  30 - Loss:   730.3490 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  31 - Loss:  1160.5336 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  32 - Loss:   702.5920 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  33 - Loss:   655.2702 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  34 - Loss:   508.3463 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  35 - Loss:   605.2529 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  36 - Loss:   900.5041 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  37 - Loss:   715.8049 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  38 - Loss:   908.7664 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  39 - Loss:   506.7295 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  40 - Loss:   560.8171 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  41 - Loss:   579.8113 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  42 - Loss:   952.1479 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  43 - Loss:   600.9067 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  44 - Loss:   753.4897 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  45 - Loss:   568.9863 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  46 - Loss:   625.7676 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  47 - Loss:   989.7146 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  48 - Loss:   806.0352 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  49 - Loss:   891.9600 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  50 - Loss:   741.9854 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  51 - Loss:   331.4015 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  52 - Loss:   784.2065 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  53 - Loss:   615.2136 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  54 - Loss:   892.3234 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  55 - Loss:   697.3732 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  56 - Loss:   685.1778 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  57 - Loss:   807.2893 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  58 - Loss:   553.4451 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  59 - Loss:   408.0616 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  60 - Loss:   730.9839 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  61 - Loss:  1009.3249 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  62 - Loss:   837.2781 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  63 - Loss:   667.2863 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  64 - Loss:   720.3066 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  65 - Loss:   601.5159 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  66 - Loss:  1012.0092 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  67 - Loss:   622.7906 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  68 - Loss:   391.0680 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  69 - Loss:   749.6110 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  70 - Loss:   886.9777 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  71 - Loss:   468.2504 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  72 - Loss:   634.0157 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  73 - Loss:   660.9990 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  74 - Loss:   613.2261 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  75 - Loss:   659.7052 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  76 - Loss:  1213.8470 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  77 - Loss:   608.7988 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  78 - Loss:   742.2651 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  79 - Loss:  1124.8169 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch  80 - Loss:   838.4332 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  81 - Loss:   949.3002 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  82 - Loss:   898.0825 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  83 - Loss:   513.2740 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  84 - Loss:  1082.8815 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  85 - Loss:   798.5530 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  86 - Loss:   805.4509 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  87 - Loss:   759.0870 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  88 - Loss:   259.8637 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  89 - Loss:   917.7500 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  90 - Loss:   467.9582 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  91 - Loss:   497.2491 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  92 - Loss:   617.1569 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  93 - Loss:   797.9773 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  94 - Loss:   693.6141 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  95 - Loss:   625.9252 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch  96 - Loss:   693.5918 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch  97 - Loss:   437.1043 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch  98 - Loss:   563.6038 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch  99 - Loss:   386.3356 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 100 - Loss:   683.1249 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 101 - Loss:   694.5671 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 102 - Loss:   309.3401 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 103 - Loss:   778.4503 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 104 - Loss:   807.8859 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 105 - Loss:   844.0900 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 106 - Loss:   840.7197 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 107 - Loss:   889.5314 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 108 - Loss:   633.4359 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 109 - Loss:   717.4671 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 110 - Loss:   798.8305 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 111 - Loss:   973.4887 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 112 - Loss:   740.6568 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 113 - Loss:   795.2653 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 114 - Loss:   635.9985 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 115 - Loss:   646.8663 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 116 - Loss:   813.8474 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 117 - Loss:   749.1383 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 118 - Loss:   486.9877 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 119 - Loss:   519.7389 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 120 - Loss:   536.0018 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 121 - Loss:   999.0568 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 122 - Loss:   680.6790 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 123 - Loss:   807.4530 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 124 - Loss:   553.5243 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 125 - Loss:   955.0229 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 126 - Loss:   723.2013 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 127 - Loss:   386.0223 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 128 - Loss:   540.9750 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 129 - Loss:   723.5797 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 130 - Loss:   678.9592 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 131 - Loss:   228.6690 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 132 - Loss:   745.1771 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 133 - Loss:   609.4182 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 134 - Loss:   511.4410 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 135 - Loss:   660.1866 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 136 - Loss:   725.4149 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 137 - Loss:   874.9728 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 138 - Loss:   605.2354 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 139 - Loss:   751.6674 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 140 - Loss:   452.5981 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 141 - Loss:   750.6393 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 142 - Loss:   545.3964 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 143 - Loss:   564.5239 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 144 - Loss:  1026.4175 Validation Accuracy: 0.816406\n",
      "Epoch  4, Batch 145 - Loss:   928.1519 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 146 - Loss:   703.8287 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 147 - Loss:   936.1589 Validation Accuracy: 0.820312\n",
      "Epoch  4, Batch 148 - Loss:   565.9253 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 149 - Loss:   988.9250 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 150 - Loss:   489.7919 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 151 - Loss:   720.4799 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 152 - Loss:  1128.8243 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 153 - Loss:   689.8760 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 154 - Loss:   862.8943 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 155 - Loss:   673.9637 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 156 - Loss:  1167.2598 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 157 - Loss:   587.5339 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 158 - Loss:  1054.4841 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 159 - Loss:   865.2266 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 160 - Loss:   747.7463 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 161 - Loss:   476.6451 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 162 - Loss:   444.8967 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 163 - Loss:  1151.4291 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 164 - Loss:   747.3560 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 165 - Loss:  1072.4833 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 166 - Loss:   584.9639 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 167 - Loss:   519.2275 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 168 - Loss:   633.7202 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 169 - Loss:   247.5845 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 170 - Loss:   505.7606 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 171 - Loss:   667.8417 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 172 - Loss:   754.0366 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 173 - Loss:   580.9941 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 174 - Loss:   612.4523 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 175 - Loss:   554.3712 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 176 - Loss:   661.9515 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 177 - Loss:   879.4921 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 178 - Loss:   746.7762 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 179 - Loss:   664.5151 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 180 - Loss:   708.5963 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 181 - Loss:   611.0485 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 182 - Loss:   389.0255 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 183 - Loss:   452.2579 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 184 - Loss:   763.4389 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 185 - Loss:   693.7419 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 186 - Loss:   559.6575 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 187 - Loss:   581.8381 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 188 - Loss:   795.6877 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 189 - Loss:   576.3147 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 190 - Loss:   936.8650 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 191 - Loss:   234.3542 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 192 - Loss:   452.9774 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 193 - Loss:   705.4257 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 194 - Loss:   673.8928 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 195 - Loss:   367.3670 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 196 - Loss:   412.5739 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 197 - Loss:   821.6090 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 198 - Loss:   684.7939 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 199 - Loss:   957.7166 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 200 - Loss:   507.2226 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 201 - Loss:   501.3324 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 202 - Loss:   796.6165 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 203 - Loss:   603.3356 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 204 - Loss:   662.6821 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 205 - Loss:   451.9347 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 206 - Loss:   552.7934 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 207 - Loss:   617.2242 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 208 - Loss:   760.7642 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 209 - Loss:   748.7362 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 210 - Loss:   857.7283 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 211 - Loss:   613.7523 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 212 - Loss:   480.8874 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 213 - Loss:   350.5328 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 214 - Loss:   798.3754 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 215 - Loss:   948.1668 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 216 - Loss:   611.2924 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 217 - Loss:   722.1515 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 218 - Loss:   735.6897 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 219 - Loss:   717.1112 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 220 - Loss:   972.4499 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 221 - Loss:   767.1066 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 222 - Loss:   736.3577 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 223 - Loss:   575.7633 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 224 - Loss:   752.5549 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 225 - Loss:   506.9410 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 226 - Loss:   755.7510 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 227 - Loss:   531.9452 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 228 - Loss:   482.5073 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 229 - Loss:  1018.5560 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 230 - Loss:   510.6516 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 231 - Loss:   657.0162 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 232 - Loss:   505.8547 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 233 - Loss:   958.5477 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 234 - Loss:   543.3260 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 235 - Loss:   458.7485 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 236 - Loss:   505.2978 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 237 - Loss:   414.4905 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 238 - Loss:   565.9924 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 239 - Loss:   542.2883 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 240 - Loss:   453.6834 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 241 - Loss:   606.4408 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 242 - Loss:   589.1315 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 243 - Loss:   586.3751 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 244 - Loss:   421.4333 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 245 - Loss:   804.1539 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 246 - Loss:   740.3458 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 247 - Loss:   978.0560 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 248 - Loss:   395.3568 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 249 - Loss:   714.2327 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 250 - Loss:   450.8210 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 251 - Loss:   651.7324 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 252 - Loss:   971.7841 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 253 - Loss:   734.6024 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 254 - Loss:   413.2009 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 255 - Loss:   542.1736 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 256 - Loss:   670.3054 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 257 - Loss:   505.4073 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 258 - Loss:   741.6486 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 259 - Loss:   986.3268 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 260 - Loss:   779.0121 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 261 - Loss:   552.6428 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 262 - Loss:   783.1861 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 263 - Loss:   592.5294 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 264 - Loss:   533.8119 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 265 - Loss:   789.6707 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 266 - Loss:   765.0936 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 267 - Loss:   377.9490 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 268 - Loss:   697.5992 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 269 - Loss:   575.0001 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 270 - Loss:   619.1463 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 271 - Loss:   657.0665 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 272 - Loss:  1143.7695 Validation Accuracy: 0.824219\n",
      "Epoch  4, Batch 273 - Loss:   633.4503 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 274 - Loss:   994.0556 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 275 - Loss:   574.6933 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 276 - Loss:   496.1363 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 277 - Loss:   543.3303 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 278 - Loss:   918.9595 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 279 - Loss:   645.9397 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 280 - Loss:   316.3838 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 281 - Loss:   811.2339 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 282 - Loss:   841.5591 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 283 - Loss:   481.0163 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 284 - Loss:   387.3335 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 285 - Loss:   535.0111 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 286 - Loss:   399.8186 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 287 - Loss:   691.5876 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 288 - Loss:   842.9541 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 289 - Loss:   747.2499 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 290 - Loss:   597.7742 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 291 - Loss:   601.3228 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 292 - Loss:   496.9037 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 293 - Loss:   908.5056 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 294 - Loss:   880.9404 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 295 - Loss:   542.1641 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 296 - Loss:   800.3052 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 297 - Loss:   562.9297 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 298 - Loss:   517.9732 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 299 - Loss:   676.3274 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 300 - Loss:   525.6717 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 301 - Loss:   709.7895 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 302 - Loss:   462.3271 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 303 - Loss:   589.0249 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 304 - Loss:   516.7203 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 305 - Loss:   548.3071 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 306 - Loss:   712.9104 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 307 - Loss:   318.4755 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 308 - Loss:   958.3497 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 309 - Loss:   721.5206 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 310 - Loss:   365.5402 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 311 - Loss:   815.0546 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 312 - Loss:   662.3763 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 313 - Loss:   677.7002 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 314 - Loss:   751.1150 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 315 - Loss:   931.7852 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 316 - Loss:   600.6942 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 317 - Loss:   389.3472 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 318 - Loss:   376.3115 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 319 - Loss:   788.9953 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 320 - Loss:   553.9841 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 321 - Loss:   534.9017 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 322 - Loss:   668.6273 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 323 - Loss:   684.0649 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 324 - Loss:   859.0121 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 325 - Loss:   646.6724 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 326 - Loss:   428.1968 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 327 - Loss:   521.5164 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 328 - Loss:   387.2411 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 329 - Loss:   394.1860 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 330 - Loss:   807.9707 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 331 - Loss:   480.5785 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 332 - Loss:   632.6982 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 333 - Loss:   484.7550 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 334 - Loss:   766.8718 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 335 - Loss:   794.8353 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 336 - Loss:   618.1888 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 337 - Loss:   445.6021 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 338 - Loss:   633.8150 Validation Accuracy: 0.847656\n",
      "Epoch  4, Batch 339 - Loss:   684.5020 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 340 - Loss:   679.0282 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 341 - Loss:   468.9799 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 342 - Loss:   858.3156 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 343 - Loss:   324.8573 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 344 - Loss:   765.9916 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 345 - Loss:   725.7900 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 346 - Loss:   640.7607 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 347 - Loss:   795.4827 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 348 - Loss:   476.4666 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 349 - Loss:   347.1546 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 350 - Loss:   404.2558 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 351 - Loss:   553.4517 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 352 - Loss:   884.2021 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 353 - Loss:   922.4916 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 354 - Loss:   530.2947 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 355 - Loss:   626.4611 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 356 - Loss:   350.3727 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 357 - Loss:   869.9287 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 358 - Loss:   627.6050 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 359 - Loss:   689.4070 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 360 - Loss:   877.5242 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 361 - Loss:   615.5548 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 362 - Loss:   438.3580 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 363 - Loss:   724.3220 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 364 - Loss:   682.9028 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 365 - Loss:   294.9662 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 366 - Loss:   566.3317 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 367 - Loss:   729.6115 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 368 - Loss:   658.3556 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 369 - Loss:   732.9423 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 370 - Loss:   904.2314 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 371 - Loss:   543.2131 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 372 - Loss:   833.7648 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 373 - Loss:   899.0273 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 374 - Loss:   742.4981 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 375 - Loss:   689.3356 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 376 - Loss:   722.2184 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 377 - Loss:   374.0716 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 378 - Loss:   777.9882 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 379 - Loss:   303.2946 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 380 - Loss:   499.2038 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 381 - Loss:   542.1804 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 382 - Loss:  1158.8765 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 383 - Loss:   413.0692 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 384 - Loss:   515.4301 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 385 - Loss:   591.2723 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 386 - Loss:   600.8354 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 387 - Loss:   529.6918 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 388 - Loss:   759.2316 Validation Accuracy: 0.828125\n",
      "Epoch  4, Batch 389 - Loss:   455.3786 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 390 - Loss:   877.1429 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 391 - Loss:   770.0348 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 392 - Loss:   594.9495 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 393 - Loss:   702.4437 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 394 - Loss:   550.8687 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 395 - Loss:   676.8001 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 396 - Loss:   739.0132 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 397 - Loss:   597.2808 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 398 - Loss:   703.6458 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 399 - Loss:   824.3113 Validation Accuracy: 0.832031\n",
      "Epoch  4, Batch 400 - Loss:   600.2598 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 401 - Loss:   465.9489 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 402 - Loss:   867.9396 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 403 - Loss:   369.2014 Validation Accuracy: 0.835938\n",
      "Epoch  4, Batch 404 - Loss:   516.9231 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 405 - Loss:   593.6543 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 406 - Loss:   515.9349 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 407 - Loss:   577.0030 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 408 - Loss:   542.8309 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 409 - Loss:   521.0483 Validation Accuracy: 0.847656\n",
      "Epoch  4, Batch 410 - Loss:   742.0483 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 411 - Loss:   330.4973 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 412 - Loss:   568.9719 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 413 - Loss:   454.4947 Validation Accuracy: 0.847656\n",
      "Epoch  4, Batch 414 - Loss:   961.1105 Validation Accuracy: 0.847656\n",
      "Epoch  4, Batch 415 - Loss:   651.6572 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 416 - Loss:   621.1083 Validation Accuracy: 0.847656\n",
      "Epoch  4, Batch 417 - Loss:   784.1921 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 418 - Loss:   400.0458 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 419 - Loss:   547.1816 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 420 - Loss:   512.3785 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 421 - Loss:   732.8041 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 422 - Loss:   580.5553 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 423 - Loss:   441.5322 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 424 - Loss:   542.4513 Validation Accuracy: 0.839844\n",
      "Epoch  4, Batch 425 - Loss:   580.3223 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 426 - Loss:  1008.0962 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 427 - Loss:   843.1211 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 428 - Loss:   725.6470 Validation Accuracy: 0.843750\n",
      "Epoch  4, Batch 429 - Loss:   705.6274 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch   1 - Loss:   580.7378 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch   2 - Loss:   506.8390 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch   3 - Loss:   608.7172 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch   4 - Loss:   439.6561 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch   5 - Loss:   684.8138 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch   6 - Loss:   567.6688 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch   7 - Loss:   602.7068 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch   8 - Loss:   669.3502 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch   9 - Loss:   850.8057 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  10 - Loss:   606.7430 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  11 - Loss:   523.2633 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  12 - Loss:   792.1246 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  13 - Loss:   571.0316 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  14 - Loss:   501.6622 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  15 - Loss:   845.2141 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  16 - Loss:   476.4442 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  17 - Loss:   973.8333 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  18 - Loss:   440.5240 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  19 - Loss:   674.5909 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  20 - Loss:   554.0755 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  21 - Loss:   679.4949 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  22 - Loss:   886.8810 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  23 - Loss:   355.9224 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  24 - Loss:   640.2375 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  25 - Loss:   559.7349 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  26 - Loss:   491.1233 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  27 - Loss:   542.9761 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  28 - Loss:   639.3546 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  29 - Loss:   866.9952 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  30 - Loss:   491.1360 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  31 - Loss:   589.6587 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  32 - Loss:   517.4356 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  33 - Loss:   591.0947 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  34 - Loss:   593.7733 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  35 - Loss:   483.1867 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  36 - Loss:   676.1331 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  37 - Loss:   322.9186 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  38 - Loss:   764.2247 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  39 - Loss:   522.3256 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch  40 - Loss:   681.7830 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  41 - Loss:   663.4529 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  42 - Loss:   554.2194 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  43 - Loss:   532.4334 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  44 - Loss:   475.2625 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  45 - Loss:   616.5271 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  46 - Loss:   789.1964 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  47 - Loss:   548.8938 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  48 - Loss:   654.4121 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  49 - Loss:   522.6660 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  50 - Loss:   483.7647 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  51 - Loss:   380.2406 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  52 - Loss:   613.0968 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  53 - Loss:   644.4305 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  54 - Loss:   468.7353 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  55 - Loss:   542.5387 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  56 - Loss:   459.6846 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch  57 - Loss:   988.2400 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  58 - Loss:   496.9153 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  59 - Loss:   467.0258 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  60 - Loss:   641.3661 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  61 - Loss:   464.5135 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  62 - Loss:   590.2985 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  63 - Loss:   817.5834 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  64 - Loss:   574.1425 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  65 - Loss:   901.1660 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  66 - Loss:   519.4128 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  67 - Loss:   605.6561 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  68 - Loss:   458.3647 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  69 - Loss:   394.1541 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  70 - Loss:   850.0679 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  71 - Loss:   565.6157 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  72 - Loss:   634.3821 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  73 - Loss:   397.2787 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  74 - Loss:   598.3043 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  75 - Loss:   669.7349 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  76 - Loss:   730.7213 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  77 - Loss:   644.5986 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  78 - Loss:   530.3040 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  79 - Loss:   842.9661 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  80 - Loss:   351.7150 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  81 - Loss:   551.9719 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  82 - Loss:   539.2518 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  83 - Loss:   954.6160 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch  84 - Loss:   630.6312 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  85 - Loss:   563.9612 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  86 - Loss:   706.0231 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  87 - Loss:   484.6107 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  88 - Loss:   716.7596 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  89 - Loss:   724.3493 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch  90 - Loss:   410.1552 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  91 - Loss:   822.7907 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  92 - Loss:   418.3478 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch  93 - Loss:   500.5563 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  94 - Loss:   291.4013 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  95 - Loss:   852.5014 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch  96 - Loss:   655.4161 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch  97 - Loss:   268.5032 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  98 - Loss:   692.0822 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch  99 - Loss:   421.0811 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 100 - Loss:   969.6219 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 101 - Loss:   574.1376 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 102 - Loss:   669.6764 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 103 - Loss:   483.4364 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 104 - Loss:   695.3793 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 105 - Loss:   686.7811 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 106 - Loss:   436.0341 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 107 - Loss:   671.3689 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 108 - Loss:   527.6086 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 109 - Loss:   788.4857 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 110 - Loss:   558.4919 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 111 - Loss:   520.3364 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 112 - Loss:   413.5497 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 113 - Loss:   461.9779 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 114 - Loss:   563.7486 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 115 - Loss:   915.8695 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 116 - Loss:   465.6589 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 117 - Loss:   706.4266 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 118 - Loss:   573.8722 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 119 - Loss:   540.0229 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 120 - Loss:   490.5811 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 121 - Loss:   357.8481 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 122 - Loss:   335.7838 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 123 - Loss:   618.6597 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 124 - Loss:   407.1841 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 125 - Loss:   648.2393 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 126 - Loss:   615.1824 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 127 - Loss:   737.7400 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 128 - Loss:   396.6174 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 129 - Loss:   722.2151 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 130 - Loss:   532.5453 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 131 - Loss:   306.8343 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 132 - Loss:   454.9987 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 133 - Loss:   647.6667 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 134 - Loss:   446.1260 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 135 - Loss:   733.9371 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 136 - Loss:   859.8168 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 137 - Loss:   633.8459 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 138 - Loss:   621.3598 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 139 - Loss:   688.6973 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 140 - Loss:   712.0388 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 141 - Loss:   489.3250 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 142 - Loss:   205.7306 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 143 - Loss:   716.9525 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 144 - Loss:   367.6206 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 145 - Loss:   487.3239 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 146 - Loss:   833.2028 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 147 - Loss:   535.5159 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 148 - Loss:   371.6660 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 149 - Loss:   657.3455 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 150 - Loss:   378.6090 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 151 - Loss:   456.2717 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 152 - Loss:   661.6310 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 153 - Loss:   733.5038 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 154 - Loss:   414.3702 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 155 - Loss:   496.4947 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 156 - Loss:   673.6573 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 157 - Loss:   609.6022 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 158 - Loss:   359.9930 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 159 - Loss:   974.0605 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 160 - Loss:   861.6661 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 161 - Loss:   755.1320 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 162 - Loss:   454.7446 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 163 - Loss:   762.9157 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 164 - Loss:   276.4521 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 165 - Loss:   506.6824 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 166 - Loss:   726.4370 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 167 - Loss:   512.3800 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 168 - Loss:   423.2430 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 169 - Loss:   576.5463 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 170 - Loss:   613.8560 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 171 - Loss:   690.4761 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 172 - Loss:   626.7208 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 173 - Loss:   389.5353 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 174 - Loss:   771.3647 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 175 - Loss:   431.3635 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 176 - Loss:   380.4797 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 177 - Loss:   495.8110 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 178 - Loss:   286.8318 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 179 - Loss:   657.1963 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 180 - Loss:   414.8832 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 181 - Loss:   538.2824 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 182 - Loss:   867.6922 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 183 - Loss:   424.6230 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 184 - Loss:   405.9179 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 185 - Loss:   504.5831 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 186 - Loss:   630.7116 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 187 - Loss:   501.6336 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 188 - Loss:   814.2996 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 189 - Loss:   307.1707 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 190 - Loss:   246.7707 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 191 - Loss:   698.2055 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 192 - Loss:   318.1849 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 193 - Loss:   503.0065 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 194 - Loss:   790.7569 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 195 - Loss:   423.3763 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 196 - Loss:   503.3451 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 197 - Loss:   727.2350 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 198 - Loss:   429.1418 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 199 - Loss:   487.2650 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 200 - Loss:   641.9137 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 201 - Loss:   503.3116 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 202 - Loss:   629.0990 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 203 - Loss:   686.8322 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 204 - Loss:   463.2933 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 205 - Loss:   621.3905 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 206 - Loss:   609.3261 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 207 - Loss:   813.7899 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 208 - Loss:   514.2402 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 209 - Loss:   560.5162 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 210 - Loss:   563.5628 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 211 - Loss:   475.3387 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 212 - Loss:   700.2495 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 213 - Loss:   569.1973 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 214 - Loss:   263.7904 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 215 - Loss:   387.5662 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 216 - Loss:   389.9445 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 217 - Loss:   463.2106 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 218 - Loss:   803.1172 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 219 - Loss:   511.6760 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 220 - Loss:   483.8575 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 221 - Loss:   552.3440 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 222 - Loss:   540.8439 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 223 - Loss:   456.5997 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 224 - Loss:   266.0888 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 225 - Loss:   472.9952 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 226 - Loss:   502.9982 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 227 - Loss:   467.4623 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 228 - Loss:   436.5587 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 229 - Loss:   515.7745 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 230 - Loss:   404.3642 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 231 - Loss:   920.6537 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 232 - Loss:   610.5423 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 233 - Loss:   666.8833 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 234 - Loss:   757.8784 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 235 - Loss:   460.5735 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 236 - Loss:   551.3126 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 237 - Loss:   216.1811 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 238 - Loss:   603.6187 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 239 - Loss:   520.1696 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 240 - Loss:   659.8311 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 241 - Loss:   749.8080 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 242 - Loss:   838.8947 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 243 - Loss:   506.3742 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 244 - Loss:   518.2412 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 245 - Loss:   467.4619 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 246 - Loss:   477.1416 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 247 - Loss:   295.6928 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 248 - Loss:   669.1342 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 249 - Loss:   793.8517 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 250 - Loss:   672.2130 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 251 - Loss:   334.9051 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 252 - Loss:   493.4160 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 253 - Loss:   616.3289 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 254 - Loss:   480.6795 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 255 - Loss:   370.0794 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 256 - Loss:   900.2994 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 257 - Loss:   363.4108 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 258 - Loss:   489.3673 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 259 - Loss:   463.8872 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 260 - Loss:   675.9497 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 261 - Loss:   428.5941 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 262 - Loss:   508.9627 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 263 - Loss:   831.1110 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 264 - Loss:   257.5778 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 265 - Loss:   401.6428 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 266 - Loss:   579.2025 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 267 - Loss:   677.8558 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 268 - Loss:   574.8653 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 269 - Loss:   868.7630 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 270 - Loss:   799.9111 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 271 - Loss:   525.5055 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 272 - Loss:   505.0001 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 273 - Loss:   471.8795 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 274 - Loss:   595.8068 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 275 - Loss:   466.4286 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 276 - Loss:   535.5354 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 277 - Loss:   611.9269 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 278 - Loss:   426.6562 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 279 - Loss:   280.6674 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 280 - Loss:   590.4895 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 281 - Loss:   510.0572 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 282 - Loss:   766.9389 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 283 - Loss:   558.1799 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 284 - Loss:   559.7330 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 285 - Loss:   587.5853 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 286 - Loss:   527.8235 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 287 - Loss:   627.4768 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 288 - Loss:   327.7432 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 289 - Loss:   366.3910 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 290 - Loss:   483.4513 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 291 - Loss:   897.4915 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 292 - Loss:   445.5699 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 293 - Loss:   402.7433 Validation Accuracy: 0.863281\n",
      "Epoch  5, Batch 294 - Loss:   573.0539 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 295 - Loss:   443.2665 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 296 - Loss:   552.8743 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 297 - Loss:   507.6485 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 298 - Loss:   656.5005 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 299 - Loss:   586.6401 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 300 - Loss:   426.5161 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 301 - Loss:   492.6444 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 302 - Loss:   651.1722 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 303 - Loss:   368.3777 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 304 - Loss:   551.6317 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 305 - Loss:   442.5004 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 306 - Loss:   262.9371 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 307 - Loss:   501.7911 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 308 - Loss:   597.0460 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 309 - Loss:   173.4552 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 310 - Loss:   610.7862 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 311 - Loss:   503.9368 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 312 - Loss:   364.2672 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 313 - Loss:   501.0460 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 314 - Loss:   754.7627 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 315 - Loss:   703.7646 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 316 - Loss:   399.3094 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 317 - Loss:   824.3240 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 318 - Loss:   540.2144 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 319 - Loss:   247.3829 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 320 - Loss:   582.5526 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 321 - Loss:   283.6323 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 322 - Loss:   842.2576 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 323 - Loss:   757.1346 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 324 - Loss:   690.9808 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 325 - Loss:   590.9065 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 326 - Loss:   551.7727 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 327 - Loss:   343.3343 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 328 - Loss:   820.7065 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 329 - Loss:   459.0002 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 330 - Loss:   371.0196 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 331 - Loss:   515.9728 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 332 - Loss:   384.5635 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 333 - Loss:   399.5118 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 334 - Loss:   416.2478 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 335 - Loss:   689.8749 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 336 - Loss:   585.6488 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 337 - Loss:   447.4291 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 338 - Loss:   601.3135 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 339 - Loss:   705.1733 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 340 - Loss:   618.5812 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 341 - Loss:   427.1307 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 342 - Loss:   370.5556 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 343 - Loss:   529.8925 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 344 - Loss:   512.0842 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 345 - Loss:   684.5576 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 346 - Loss:   561.1409 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 347 - Loss:   472.8401 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 348 - Loss:   577.1487 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 349 - Loss:   417.8207 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 350 - Loss:   167.0316 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 351 - Loss:   758.5961 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 352 - Loss:   716.0007 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 353 - Loss:   520.2129 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 354 - Loss:   522.7882 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 355 - Loss:   671.6580 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 356 - Loss:   672.5994 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 357 - Loss:   517.7922 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 358 - Loss:   365.6595 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 359 - Loss:   436.4373 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 360 - Loss:   301.1371 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 361 - Loss:   527.2824 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 362 - Loss:   334.6782 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 363 - Loss:   426.1099 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 364 - Loss:   303.4639 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 365 - Loss:   672.7605 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 366 - Loss:   714.7281 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 367 - Loss:   558.1334 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 368 - Loss:   489.5773 Validation Accuracy: 0.839844\n",
      "Epoch  5, Batch 369 - Loss:   162.0246 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 370 - Loss:   629.4168 Validation Accuracy: 0.843750\n",
      "Epoch  5, Batch 371 - Loss:   379.9959 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 372 - Loss:   601.3208 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 373 - Loss:   486.4029 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 374 - Loss:   477.1538 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 375 - Loss:   524.2910 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 376 - Loss:   220.4527 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 377 - Loss:   505.8917 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 378 - Loss:   553.7247 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 379 - Loss:   534.1353 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 380 - Loss:   639.6681 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 381 - Loss:   768.0333 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 382 - Loss:   974.7772 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 383 - Loss:   555.4260 Validation Accuracy: 0.863281\n",
      "Epoch  5, Batch 384 - Loss:   430.1119 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 385 - Loss:   382.1851 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 386 - Loss:   553.6802 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 387 - Loss:   825.2621 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 388 - Loss:   633.9659 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 389 - Loss:   457.9634 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 390 - Loss:   699.3348 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 391 - Loss:   343.2556 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 392 - Loss:   533.8453 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 393 - Loss:   678.8581 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 394 - Loss:   387.7032 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 395 - Loss:   590.4664 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 396 - Loss:   620.8560 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 397 - Loss:   564.9432 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 398 - Loss:   513.4678 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 399 - Loss:   252.6754 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 400 - Loss:   514.7847 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 401 - Loss:   379.0420 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 402 - Loss:   279.7983 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 403 - Loss:   399.8516 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 404 - Loss:   719.7649 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 405 - Loss:   376.0730 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 406 - Loss:   384.2988 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 407 - Loss:   516.6306 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 408 - Loss:   732.9860 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 409 - Loss:   605.4796 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 410 - Loss:   385.3580 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 411 - Loss:   639.5558 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 412 - Loss:   593.9867 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 413 - Loss:   497.9607 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 414 - Loss:   424.1655 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 415 - Loss:   808.9220 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 416 - Loss:   760.7108 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 417 - Loss:   354.4537 Validation Accuracy: 0.847656\n",
      "Epoch  5, Batch 418 - Loss:   408.4082 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 419 - Loss:   354.0425 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 420 - Loss:   643.4843 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 421 - Loss:   620.3788 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 422 - Loss:   746.4341 Validation Accuracy: 0.859375\n",
      "Epoch  5, Batch 423 - Loss:   486.0620 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 424 - Loss:   685.3767 Validation Accuracy: 0.855469\n",
      "Epoch  5, Batch 425 - Loss:   344.0162 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 426 - Loss:   507.7128 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 427 - Loss:   376.3698 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 428 - Loss:   534.6857 Validation Accuracy: 0.851562\n",
      "Epoch  5, Batch 429 - Loss:   457.5677 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch   1 - Loss:   935.2762 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch   2 - Loss:   432.4089 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch   3 - Loss:   312.4483 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch   4 - Loss:   347.4521 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch   5 - Loss:   778.9713 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch   6 - Loss:   239.4231 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch   7 - Loss:   504.5078 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch   8 - Loss:   448.0427 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch   9 - Loss:   459.2988 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  10 - Loss:   691.8739 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  11 - Loss:   336.5059 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch  12 - Loss:   693.4509 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  13 - Loss:   364.5261 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  14 - Loss:   507.3086 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  15 - Loss:   680.2773 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  16 - Loss:   568.1554 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  17 - Loss:   352.0670 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  18 - Loss:   322.2819 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  19 - Loss:   503.4691 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  20 - Loss:   554.1720 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  21 - Loss:   347.4111 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  22 - Loss:   228.8155 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  23 - Loss:   306.0354 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  24 - Loss:   214.0538 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  25 - Loss:   731.5590 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  26 - Loss:   395.7939 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  27 - Loss:   493.5051 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  28 - Loss:   319.2550 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  29 - Loss:   528.9352 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  30 - Loss:   379.0539 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  31 - Loss:   682.4293 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch  32 - Loss:   715.4127 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch  33 - Loss:   514.5072 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  34 - Loss:   532.3131 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch  35 - Loss:   588.7542 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch  36 - Loss:   476.7308 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  37 - Loss:   420.3125 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch  38 - Loss:   554.1483 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  39 - Loss:   667.1406 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  40 - Loss:   306.8852 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch  41 - Loss:   202.7995 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  42 - Loss:   369.2315 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  43 - Loss:   362.0358 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch  44 - Loss:   179.0331 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  45 - Loss:   421.9523 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch  46 - Loss:   602.2042 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  47 - Loss:   504.5067 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch  48 - Loss:   835.4174 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  49 - Loss:   631.1895 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  50 - Loss:   575.2300 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch  51 - Loss:   652.8159 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  52 - Loss:   298.9973 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  53 - Loss:   726.3242 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  54 - Loss:   306.1900 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  55 - Loss:   630.9418 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  56 - Loss:   468.7495 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  57 - Loss:   588.0699 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  58 - Loss:   365.0518 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  59 - Loss:   468.0445 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  60 - Loss:   484.4828 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  61 - Loss:   584.5961 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  62 - Loss:   743.8450 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  63 - Loss:   329.9692 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  64 - Loss:   352.5557 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch  65 - Loss:   547.9091 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  66 - Loss:   617.2427 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  67 - Loss:   612.3486 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  68 - Loss:   513.7406 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  69 - Loss:   542.8000 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  70 - Loss:   541.5874 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  71 - Loss:   475.4087 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  72 - Loss:   418.1265 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  73 - Loss:   391.3976 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  74 - Loss:   534.4689 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  75 - Loss:   620.1476 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  76 - Loss:   439.0658 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  77 - Loss:   486.3405 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  78 - Loss:   475.1215 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  79 - Loss:   442.2072 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  80 - Loss:   431.5027 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  81 - Loss:   733.4514 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  82 - Loss:   680.3206 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  83 - Loss:   519.6263 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  84 - Loss:   332.6650 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  85 - Loss:   332.1722 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  86 - Loss:   513.3596 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  87 - Loss:   666.3878 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  88 - Loss:   548.9946 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  89 - Loss:   292.8169 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  90 - Loss:   572.0560 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  91 - Loss:   610.6625 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch  92 - Loss:   353.0166 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  93 - Loss:   433.4565 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  94 - Loss:   537.2532 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  95 - Loss:   437.3163 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  96 - Loss:   304.6872 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch  97 - Loss:   180.4313 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch  98 - Loss:   505.4926 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch  99 - Loss:   486.7032 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 100 - Loss:   624.1170 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 101 - Loss:   544.5625 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 102 - Loss:   533.1528 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 103 - Loss:   476.3934 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 104 - Loss:   520.8988 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 105 - Loss:   606.8964 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 106 - Loss:   426.2650 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 107 - Loss:   279.8483 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 108 - Loss:   502.1139 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 109 - Loss:   380.1313 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 110 - Loss:   383.3212 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 111 - Loss:   312.6708 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 112 - Loss:   619.6667 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 113 - Loss:   336.4786 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 114 - Loss:   622.4869 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 115 - Loss:   836.4497 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 116 - Loss:   565.9423 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 117 - Loss:   738.5700 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 118 - Loss:   438.1406 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 119 - Loss:   595.0929 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 120 - Loss:   592.7234 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 121 - Loss:   301.1168 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 122 - Loss:   365.6864 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 123 - Loss:   421.8404 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 124 - Loss:   448.4964 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 125 - Loss:   343.3598 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 126 - Loss:   293.8282 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 127 - Loss:   600.9242 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 128 - Loss:   410.2156 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 129 - Loss:   487.9391 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 130 - Loss:   356.6567 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 131 - Loss:   660.3932 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 132 - Loss:   388.3106 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 133 - Loss:   435.8216 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 134 - Loss:   406.5002 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 135 - Loss:   491.5913 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 136 - Loss:   505.5452 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 137 - Loss:   540.8755 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 138 - Loss:   632.1472 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 139 - Loss:   382.3231 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 140 - Loss:   309.6685 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 141 - Loss:   435.6091 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 142 - Loss:   386.3353 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 143 - Loss:   358.3660 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 144 - Loss:   435.5007 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 145 - Loss:   442.0112 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 146 - Loss:   618.8264 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 147 - Loss:   332.2783 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 148 - Loss:   341.2578 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 149 - Loss:   407.6077 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 150 - Loss:   420.4035 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 151 - Loss:   276.9410 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 152 - Loss:   500.6386 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 153 - Loss:   574.4097 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 154 - Loss:   316.0850 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 155 - Loss:   668.1304 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 156 - Loss:   316.1634 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 157 - Loss:   784.4152 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 158 - Loss:   552.3716 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 159 - Loss:   380.1530 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 160 - Loss:   519.6953 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 161 - Loss:   248.3168 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 162 - Loss:   691.5842 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 163 - Loss:   346.9650 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 164 - Loss:   511.5368 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 165 - Loss:   381.3348 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 166 - Loss:   474.1117 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 167 - Loss:   841.3075 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 168 - Loss:   685.1038 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 169 - Loss:   416.3076 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 170 - Loss:   636.4326 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 171 - Loss:   667.6626 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 172 - Loss:   530.6039 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 173 - Loss:   517.3152 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 174 - Loss:   356.5894 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 175 - Loss:   445.0370 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 176 - Loss:   456.8491 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 177 - Loss:   598.3195 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 178 - Loss:   542.3654 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 179 - Loss:   167.6325 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 180 - Loss:   442.3097 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 181 - Loss:   430.3600 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 182 - Loss:   299.1161 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 183 - Loss:   371.5947 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 184 - Loss:   578.9801 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 185 - Loss:   452.8488 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 186 - Loss:   528.7014 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 187 - Loss:   401.0073 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 188 - Loss:   563.9593 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 189 - Loss:   561.0201 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 190 - Loss:   394.0898 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 191 - Loss:   537.4592 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 192 - Loss:   591.0691 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 193 - Loss:   477.0321 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 194 - Loss:   548.1564 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 195 - Loss:   517.7202 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 196 - Loss:   531.9856 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 197 - Loss:   493.8903 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 198 - Loss:   426.3082 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 199 - Loss:   604.3339 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 200 - Loss:   682.4062 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 201 - Loss:   489.6705 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 202 - Loss:   727.2308 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 203 - Loss:   537.7993 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 204 - Loss:   385.1956 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 205 - Loss:   525.8960 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 206 - Loss:   376.8469 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 207 - Loss:   570.7158 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 208 - Loss:   496.1607 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 209 - Loss:   514.8239 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 210 - Loss:   522.6236 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 211 - Loss:   685.1827 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 212 - Loss:   658.0604 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 213 - Loss:   284.8630 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 214 - Loss:   380.5262 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 215 - Loss:   544.6666 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 216 - Loss:   213.9904 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 217 - Loss:   193.1062 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 218 - Loss:   254.4263 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 219 - Loss:   464.0326 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 220 - Loss:   441.3229 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 221 - Loss:   693.4926 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 222 - Loss:   235.9153 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 223 - Loss:   256.6570 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 224 - Loss:   619.9778 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 225 - Loss:   357.6367 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 226 - Loss:   533.4510 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 227 - Loss:   439.6060 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 228 - Loss:   692.0089 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 229 - Loss:   526.4733 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 230 - Loss:   523.0865 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 231 - Loss:   536.1055 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 232 - Loss:   358.8694 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 233 - Loss:   465.3607 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 234 - Loss:   190.7529 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 235 - Loss:   717.2729 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 236 - Loss:   380.4777 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 237 - Loss:   695.7578 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 238 - Loss:   415.7947 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 239 - Loss:   735.7869 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 240 - Loss:   516.7099 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 241 - Loss:   536.9852 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 242 - Loss:   591.5298 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 243 - Loss:   344.1075 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 244 - Loss:   570.5681 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 245 - Loss:   687.7249 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 246 - Loss:   502.1494 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 247 - Loss:   491.2222 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 248 - Loss:   550.8558 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 249 - Loss:   515.3685 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 250 - Loss:   437.9427 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 251 - Loss:   485.8766 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 252 - Loss:   377.8664 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 253 - Loss:   237.6428 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 254 - Loss:   326.4085 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 255 - Loss:   513.6549 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 256 - Loss:   475.9371 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 257 - Loss:   317.9062 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 258 - Loss:   626.2495 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 259 - Loss:   639.4088 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 260 - Loss:   270.6823 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 261 - Loss:   261.1333 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 262 - Loss:   708.7277 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 263 - Loss:   339.4797 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 264 - Loss:   661.4484 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 265 - Loss:   431.4547 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 266 - Loss:   520.1705 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 267 - Loss:   558.2782 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 268 - Loss:   401.1832 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 269 - Loss:   353.6649 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 270 - Loss:   523.5128 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 271 - Loss:   587.8661 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 272 - Loss:   350.5792 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 273 - Loss:   393.8283 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 274 - Loss:   639.3893 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 275 - Loss:   432.5253 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 276 - Loss:   435.2070 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 277 - Loss:   554.7021 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 278 - Loss:   277.4523 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 279 - Loss:   491.6185 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 280 - Loss:   646.0402 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 281 - Loss:   881.1375 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch 282 - Loss:   622.7719 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch 283 - Loss:   357.5920 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 284 - Loss:   307.3462 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 285 - Loss:   325.4756 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 286 - Loss:   264.5003 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 287 - Loss:   615.0705 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 288 - Loss:   666.5920 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch 289 - Loss:   500.5852 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 290 - Loss:   536.3234 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 291 - Loss:   394.6257 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 292 - Loss:   504.8346 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 293 - Loss:   372.4219 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 294 - Loss:   539.2122 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 295 - Loss:   328.4590 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 296 - Loss:   327.3747 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch 297 - Loss:   471.4410 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 298 - Loss:   408.2612 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 299 - Loss:   469.9087 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 300 - Loss:   708.8297 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 301 - Loss:   640.8140 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 302 - Loss:   197.1723 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 303 - Loss:   432.1280 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 304 - Loss:   388.7993 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 305 - Loss:   343.5128 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 306 - Loss:   389.3712 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 307 - Loss:   247.2171 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 308 - Loss:   586.4239 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 309 - Loss:   646.5558 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 310 - Loss:   380.2568 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 311 - Loss:   430.1906 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 312 - Loss:   450.7000 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 313 - Loss:   526.0071 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 314 - Loss:   546.2977 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 315 - Loss:   342.7461 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 316 - Loss:   235.5966 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 317 - Loss:   400.2391 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 318 - Loss:   222.1857 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 319 - Loss:   595.5112 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 320 - Loss:   663.5397 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 321 - Loss:   642.5707 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 322 - Loss:   392.8174 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 323 - Loss:   435.6482 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 324 - Loss:   548.3759 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 325 - Loss:   644.5753 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 326 - Loss:   352.0653 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 327 - Loss:   362.2246 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 328 - Loss:   557.5502 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch 329 - Loss:   315.7744 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 330 - Loss:   561.0801 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch 331 - Loss:   435.1988 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch 332 - Loss:   655.7360 Validation Accuracy: 0.859375\n",
      "Epoch  6, Batch 333 - Loss:   566.0331 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch 334 - Loss:   392.9317 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 335 - Loss:   440.9925 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 336 - Loss:   773.0660 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 337 - Loss:   421.9868 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 338 - Loss:   274.1490 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 339 - Loss:   478.8344 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 340 - Loss:   383.5523 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch 341 - Loss:   434.1693 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 342 - Loss:   234.0299 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 343 - Loss:   443.2663 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 344 - Loss:   523.4951 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 345 - Loss:   478.6863 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 346 - Loss:   386.2689 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 347 - Loss:   647.5927 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 348 - Loss:   661.7783 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 349 - Loss:   857.5228 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 350 - Loss:   396.5236 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 351 - Loss:   423.9604 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 352 - Loss:   417.1048 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 353 - Loss:   512.9286 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 354 - Loss:   504.9351 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 355 - Loss:   587.5543 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 356 - Loss:   250.3547 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 357 - Loss:   498.1631 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 358 - Loss:   295.8064 Validation Accuracy: 0.835938\n",
      "Epoch  6, Batch 359 - Loss:   663.0770 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 360 - Loss:   564.3311 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 361 - Loss:   392.3130 Validation Accuracy: 0.839844\n",
      "Epoch  6, Batch 362 - Loss:   423.2726 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 363 - Loss:   420.5478 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 364 - Loss:   491.5903 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 365 - Loss:   201.6503 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 366 - Loss:   692.3633 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 367 - Loss:   620.1080 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 368 - Loss:   486.9985 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 369 - Loss:   348.9664 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 370 - Loss:   248.5274 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 371 - Loss:   424.5492 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 372 - Loss:   494.1882 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 373 - Loss:   475.8683 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 374 - Loss:   537.7900 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 375 - Loss:   491.7147 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 376 - Loss:   362.9414 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 377 - Loss:   540.3792 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 378 - Loss:   567.6105 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 379 - Loss:   398.9500 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 380 - Loss:   394.7862 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 381 - Loss:   394.1288 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 382 - Loss:   426.2534 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 383 - Loss:   643.6375 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 384 - Loss:   644.4651 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 385 - Loss:   431.6315 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 386 - Loss:   348.8791 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 387 - Loss:   666.2812 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 388 - Loss:   276.5133 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 389 - Loss:   491.1305 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 390 - Loss:   268.1749 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 391 - Loss:   774.9002 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 392 - Loss:   731.9169 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 393 - Loss:   227.1678 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 394 - Loss:   294.2885 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 395 - Loss:   213.4778 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 396 - Loss:   498.6132 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 397 - Loss:   660.3163 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 398 - Loss:   649.7170 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 399 - Loss:   649.3522 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 400 - Loss:   345.4200 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 401 - Loss:   600.6268 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 402 - Loss:   625.7446 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 403 - Loss:   650.1213 Validation Accuracy: 0.855469\n",
      "Epoch  6, Batch 404 - Loss:   487.1416 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 405 - Loss:   601.3251 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 406 - Loss:   162.8254 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 407 - Loss:   620.1537 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 408 - Loss:   559.1879 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 409 - Loss:   488.3746 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 410 - Loss:   420.0137 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 411 - Loss:   244.2712 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 412 - Loss:   384.1055 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 413 - Loss:   599.7401 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 414 - Loss:   534.7611 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 415 - Loss:   473.5753 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 416 - Loss:   323.1200 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 417 - Loss:   469.0349 Validation Accuracy: 0.851562\n",
      "Epoch  6, Batch 418 - Loss:   511.8826 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 419 - Loss:   541.3605 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 420 - Loss:   855.4886 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 421 - Loss:   305.4796 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 422 - Loss:   512.9899 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 423 - Loss:   429.7293 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 424 - Loss:   420.0992 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 425 - Loss:   501.1577 Validation Accuracy: 0.843750\n",
      "Epoch  6, Batch 426 - Loss:   627.9404 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 427 - Loss:   306.0342 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 428 - Loss:   303.1707 Validation Accuracy: 0.847656\n",
      "Epoch  6, Batch 429 - Loss:   285.9594 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   1 - Loss:   265.9640 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   2 - Loss:   685.0876 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch   3 - Loss:   395.1240 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch   4 - Loss:   250.9590 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   5 - Loss:   281.9730 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   6 - Loss:   519.1959 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch   7 - Loss:   413.9714 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch   8 - Loss:   462.0844 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch   9 - Loss:   349.7114 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  10 - Loss:   388.8628 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  11 - Loss:   376.9240 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  12 - Loss:   573.9135 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  13 - Loss:   423.9750 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  14 - Loss:   357.2893 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  15 - Loss:   301.3862 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  16 - Loss:   554.7350 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  17 - Loss:   363.4066 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  18 - Loss:   386.9187 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  19 - Loss:   304.4507 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  20 - Loss:   462.0388 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  21 - Loss:   317.6606 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  22 - Loss:   479.2465 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  23 - Loss:   616.0598 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  24 - Loss:   536.9784 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  25 - Loss:   383.4539 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  26 - Loss:   434.6459 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  27 - Loss:   723.0973 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  28 - Loss:   248.9903 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  29 - Loss:   353.0638 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  30 - Loss:   632.4026 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  31 - Loss:   473.5847 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  32 - Loss:   415.5886 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  33 - Loss:   300.4648 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  34 - Loss:   308.0201 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  35 - Loss:   319.3214 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  36 - Loss:   373.7513 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  37 - Loss:   677.8783 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  38 - Loss:   750.3176 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  39 - Loss:   242.5668 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  40 - Loss:   684.9832 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  41 - Loss:   388.8292 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  42 - Loss:   538.2448 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  43 - Loss:   482.7624 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  44 - Loss:   452.8020 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  45 - Loss:   387.5648 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  46 - Loss:   461.6873 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  47 - Loss:   642.8619 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  48 - Loss:   302.2674 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  49 - Loss:   317.1079 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  50 - Loss:   301.0178 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  51 - Loss:   342.0960 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  52 - Loss:   585.6855 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  53 - Loss:   541.9555 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  54 - Loss:   430.7718 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  55 - Loss:   268.0260 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  56 - Loss:   722.2463 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  57 - Loss:   467.2964 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  58 - Loss:   424.0551 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  59 - Loss:   400.3342 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  60 - Loss:   451.3407 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  61 - Loss:   488.0625 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  62 - Loss:   354.9401 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  63 - Loss:   632.9010 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  64 - Loss:   449.2354 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  65 - Loss:   328.5001 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  66 - Loss:   497.8799 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch  67 - Loss:   363.4120 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  68 - Loss:   375.2615 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  69 - Loss:   291.9566 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  70 - Loss:   487.0322 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  71 - Loss:   551.5400 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  72 - Loss:   308.3479 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  73 - Loss:   316.5969 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  74 - Loss:   659.6108 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  75 - Loss:   539.7598 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  76 - Loss:   430.9796 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  77 - Loss:   548.6241 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch  78 - Loss:   119.1241 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  79 - Loss:   797.1657 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  80 - Loss:   498.6404 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  81 - Loss:   447.0435 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  82 - Loss:   444.2846 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  83 - Loss:   434.2988 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  84 - Loss:   435.2379 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  85 - Loss:   294.6248 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  86 - Loss:   451.8956 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  87 - Loss:   386.0879 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  88 - Loss:   616.8694 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  89 - Loss:   305.9597 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch  90 - Loss:   396.7530 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  91 - Loss:   397.4510 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  92 - Loss:   374.7808 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch  93 - Loss:   498.3180 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  94 - Loss:   555.4091 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  95 - Loss:   447.6484 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  96 - Loss:   535.3200 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch  97 - Loss:   458.0497 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  98 - Loss:   550.9938 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch  99 - Loss:   494.4302 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 100 - Loss:   414.9982 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 101 - Loss:   413.9653 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 102 - Loss:   346.2726 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 103 - Loss:   348.8110 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 104 - Loss:   611.3909 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 105 - Loss:   482.7040 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 106 - Loss:   434.6036 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 107 - Loss:   427.4291 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 108 - Loss:   215.5339 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 109 - Loss:   727.2235 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 110 - Loss:   437.2477 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 111 - Loss:   360.3601 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 112 - Loss:   303.9089 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 113 - Loss:   283.2143 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 114 - Loss:   390.5879 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 115 - Loss:   551.3743 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 116 - Loss:   402.5696 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 117 - Loss:   450.5038 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 118 - Loss:   340.1929 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 119 - Loss:   348.0218 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 120 - Loss:   491.8040 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 121 - Loss:   450.8628 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 122 - Loss:   674.8215 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 123 - Loss:   511.4432 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 124 - Loss:   287.5960 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 125 - Loss:   493.3364 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 126 - Loss:   369.2968 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 127 - Loss:   518.5479 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 128 - Loss:   297.2723 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 129 - Loss:   766.9881 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 130 - Loss:   251.0921 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 131 - Loss:   361.7422 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 132 - Loss:   414.8599 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 133 - Loss:   408.3125 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 134 - Loss:   292.0388 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 135 - Loss:   573.1466 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 136 - Loss:   556.3821 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 137 - Loss:   412.9712 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 138 - Loss:   484.7329 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 139 - Loss:   445.5036 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 140 - Loss:   319.8679 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 141 - Loss:   512.9499 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 142 - Loss:   484.2591 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 143 - Loss:   388.5412 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 144 - Loss:   546.0357 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 145 - Loss:   361.0248 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 146 - Loss:   555.0950 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 147 - Loss:   547.8436 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 148 - Loss:   519.3463 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 149 - Loss:   542.6691 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 150 - Loss:   433.3309 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 151 - Loss:   500.9191 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 152 - Loss:   628.4098 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 153 - Loss:   341.3154 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 154 - Loss:   420.9106 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 155 - Loss:   460.5135 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 156 - Loss:   359.7343 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 157 - Loss:   671.9330 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 158 - Loss:   263.6696 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 159 - Loss:   484.3688 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 160 - Loss:   378.1371 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 161 - Loss:   503.0381 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 162 - Loss:   173.0006 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 163 - Loss:   239.0038 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 164 - Loss:   359.6849 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 165 - Loss:   591.2928 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 166 - Loss:   604.0224 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 167 - Loss:   348.6909 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 168 - Loss:   314.9777 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 169 - Loss:   455.5895 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 170 - Loss:   375.2136 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 171 - Loss:   651.8679 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 172 - Loss:   296.1172 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 173 - Loss:   557.0702 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 174 - Loss:   463.4393 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 175 - Loss:   577.7452 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 176 - Loss:   454.4941 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 177 - Loss:   348.7131 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 178 - Loss:   458.6936 Validation Accuracy: 0.867188\n",
      "Epoch  7, Batch 179 - Loss:   507.2736 Validation Accuracy: 0.867188\n",
      "Epoch  7, Batch 180 - Loss:   285.8171 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 181 - Loss:   371.9008 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 182 - Loss:   243.8498 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 183 - Loss:   502.1006 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 184 - Loss:   436.5781 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 185 - Loss:   274.8714 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 186 - Loss:   391.9019 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 187 - Loss:   222.1088 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 188 - Loss:   491.7095 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 189 - Loss:   343.5755 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 190 - Loss:   404.6741 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 191 - Loss:   413.2654 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 192 - Loss:   272.7906 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 193 - Loss:   601.4807 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 194 - Loss:   502.0500 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 195 - Loss:   389.4346 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 196 - Loss:   611.4586 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 197 - Loss:   734.6476 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 198 - Loss:   470.9502 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 199 - Loss:   417.9698 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 200 - Loss:   490.4330 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 201 - Loss:   353.3264 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 202 - Loss:   244.3544 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 203 - Loss:   465.6127 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 204 - Loss:   476.7097 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 205 - Loss:   381.4106 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 206 - Loss:   547.0541 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 207 - Loss:   214.8529 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 208 - Loss:   359.0397 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 209 - Loss:   375.6908 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 210 - Loss:   625.4390 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 211 - Loss:   406.9518 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 212 - Loss:   421.6888 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 213 - Loss:   388.0790 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 214 - Loss:   340.7657 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 215 - Loss:   497.1389 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 216 - Loss:   277.8398 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 217 - Loss:   397.1682 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 218 - Loss:   474.2538 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 219 - Loss:   391.9854 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 220 - Loss:   439.7650 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 221 - Loss:   431.1096 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 222 - Loss:   307.1238 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 223 - Loss:   456.9744 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 224 - Loss:   601.3099 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 225 - Loss:   317.0046 Validation Accuracy: 0.867188\n",
      "Epoch  7, Batch 226 - Loss:   503.9168 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 227 - Loss:   403.9070 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 228 - Loss:   536.8054 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 229 - Loss:   308.5826 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 230 - Loss:   529.0659 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 231 - Loss:   337.9263 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 232 - Loss:   641.3015 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 233 - Loss:   405.4562 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 234 - Loss:   355.2942 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 235 - Loss:   361.2825 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 236 - Loss:   516.8343 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 237 - Loss:   382.4546 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 238 - Loss:   418.4531 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 239 - Loss:   527.9249 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 240 - Loss:   477.6577 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 241 - Loss:   421.2574 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 242 - Loss:   611.1616 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 243 - Loss:   309.5869 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 244 - Loss:   561.6987 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 245 - Loss:   297.2745 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 246 - Loss:   428.8734 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 247 - Loss:   550.6068 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 248 - Loss:   490.8641 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 249 - Loss:   619.5479 Validation Accuracy: 0.863281\n",
      "Epoch  7, Batch 250 - Loss:   558.5518 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 251 - Loss:   368.2405 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 252 - Loss:   253.3167 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 253 - Loss:   364.8611 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 254 - Loss:   540.9827 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 255 - Loss:   615.2239 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 256 - Loss:   338.4515 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 257 - Loss:   376.7825 Validation Accuracy: 0.859375\n",
      "Epoch  7, Batch 258 - Loss:   468.7982 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 259 - Loss:   757.6075 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 260 - Loss:   234.3931 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 261 - Loss:   302.7712 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 262 - Loss:   549.6454 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 263 - Loss:   339.9246 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 264 - Loss:   470.5902 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 265 - Loss:   284.4438 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 266 - Loss:   313.7943 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 267 - Loss:   463.7629 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 268 - Loss:   447.8813 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 269 - Loss:   439.8597 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 270 - Loss:   528.6977 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 271 - Loss:   254.8346 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 272 - Loss:   503.0561 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 273 - Loss:   388.0268 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 274 - Loss:   451.3195 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 275 - Loss:   515.5967 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 276 - Loss:   472.7958 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 277 - Loss:   346.7867 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 278 - Loss:   146.9093 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 279 - Loss:   352.4253 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 280 - Loss:   451.9162 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 281 - Loss:   314.7167 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 282 - Loss:   477.1063 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 283 - Loss:   357.8714 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 284 - Loss:   266.3724 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 285 - Loss:   345.0426 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 286 - Loss:   362.4897 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 287 - Loss:   551.3584 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 288 - Loss:   280.8903 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 289 - Loss:   423.7000 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 290 - Loss:   479.1689 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 291 - Loss:   474.3487 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 292 - Loss:   467.9309 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 293 - Loss:   827.3557 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 294 - Loss:   340.2631 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 295 - Loss:   420.8929 Validation Accuracy: 0.855469\n",
      "Epoch  7, Batch 296 - Loss:   359.6979 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 297 - Loss:   454.6721 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 298 - Loss:   446.1765 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 299 - Loss:   226.4516 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 300 - Loss:   455.7258 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 301 - Loss:   336.1329 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 302 - Loss:   370.6982 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 303 - Loss:   400.7033 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 304 - Loss:   468.6324 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 305 - Loss:   434.4449 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 306 - Loss:   510.1824 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 307 - Loss:   570.5189 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 308 - Loss:   201.4635 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 309 - Loss:   238.8108 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 310 - Loss:   289.7002 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 311 - Loss:   333.7251 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 312 - Loss:   266.8289 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 313 - Loss:   352.9409 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 314 - Loss:   347.2314 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 315 - Loss:   435.5014 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 316 - Loss:   406.9324 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 317 - Loss:   206.4729 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 318 - Loss:   357.3307 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 319 - Loss:   354.1115 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 320 - Loss:   431.5650 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 321 - Loss:   389.7517 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 322 - Loss:   385.2903 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 323 - Loss:   383.9482 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 324 - Loss:   578.0258 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 325 - Loss:   607.9197 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 326 - Loss:   348.9547 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 327 - Loss:   360.8527 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 328 - Loss:   298.6574 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 329 - Loss:   321.3493 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 330 - Loss:   240.5321 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 331 - Loss:   543.4114 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 332 - Loss:   636.3287 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 333 - Loss:   344.1401 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 334 - Loss:   349.8977 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 335 - Loss:   421.4695 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 336 - Loss:   382.4444 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 337 - Loss:   238.4820 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 338 - Loss:   712.7535 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 339 - Loss:   345.9534 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 340 - Loss:   324.7571 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 341 - Loss:   293.5328 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 342 - Loss:   508.8781 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 343 - Loss:   511.8839 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 344 - Loss:   367.2279 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 345 - Loss:   522.1397 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 346 - Loss:   362.4067 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 347 - Loss:   524.2174 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 348 - Loss:   255.4765 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 349 - Loss:   479.9684 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 350 - Loss:   496.6696 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 351 - Loss:   357.6426 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 352 - Loss:   560.0813 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 353 - Loss:   289.0967 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 354 - Loss:   444.0913 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 355 - Loss:   455.5471 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 356 - Loss:   367.0300 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 357 - Loss:   351.2874 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 358 - Loss:   627.5613 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 359 - Loss:   493.6550 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 360 - Loss:   233.5629 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 361 - Loss:   334.5345 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 362 - Loss:   428.3030 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 363 - Loss:   499.2794 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 364 - Loss:   478.9135 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 365 - Loss:   340.0732 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 366 - Loss:   514.2227 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 367 - Loss:   394.5696 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 368 - Loss:   331.9615 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 369 - Loss:   163.3049 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 370 - Loss:   559.0765 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 371 - Loss:   183.7647 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 372 - Loss:   482.4835 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 373 - Loss:   355.4411 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 374 - Loss:   505.5890 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 375 - Loss:   488.5653 Validation Accuracy: 0.835938\n",
      "Epoch  7, Batch 376 - Loss:   451.1043 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 377 - Loss:   611.8837 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 378 - Loss:   478.4091 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 379 - Loss:   520.1705 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 380 - Loss:   235.7316 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 381 - Loss:   453.9413 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 382 - Loss:   467.2711 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 383 - Loss:   556.9750 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 384 - Loss:   425.5733 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 385 - Loss:   229.7652 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 386 - Loss:   411.6378 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 387 - Loss:   557.9970 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 388 - Loss:   474.2535 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 389 - Loss:   409.5937 Validation Accuracy: 0.839844\n",
      "Epoch  7, Batch 390 - Loss:   271.0897 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 391 - Loss:   381.9207 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 392 - Loss:   276.7579 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 393 - Loss:   586.7393 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 394 - Loss:   594.3238 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 395 - Loss:   411.6082 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 396 - Loss:   282.1763 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 397 - Loss:   576.9956 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 398 - Loss:   598.3886 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 399 - Loss:   334.0770 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 400 - Loss:   284.7029 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 401 - Loss:   370.9856 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 402 - Loss:   504.1400 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 403 - Loss:   539.8807 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 404 - Loss:   182.3813 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 405 - Loss:   360.1623 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 406 - Loss:   395.0275 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 407 - Loss:   218.0132 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 408 - Loss:   310.8740 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 409 - Loss:   621.3126 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 410 - Loss:   350.2101 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 411 - Loss:   169.5680 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 412 - Loss:   307.1458 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 413 - Loss:   445.0094 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 414 - Loss:   513.5646 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 415 - Loss:   313.2624 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 416 - Loss:   436.9380 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 417 - Loss:   274.7407 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 418 - Loss:   453.8846 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 419 - Loss:   395.2429 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 420 - Loss:   249.1641 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 421 - Loss:   334.2592 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 422 - Loss:   427.1721 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 423 - Loss:   525.3515 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 424 - Loss:   377.6085 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 425 - Loss:   408.0679 Validation Accuracy: 0.847656\n",
      "Epoch  7, Batch 426 - Loss:   540.5523 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 427 - Loss:   309.3495 Validation Accuracy: 0.851562\n",
      "Epoch  7, Batch 428 - Loss:   451.1725 Validation Accuracy: 0.843750\n",
      "Epoch  7, Batch 429 - Loss:   252.2903 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch   1 - Loss:   206.0918 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch   2 - Loss:   604.9772 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch   3 - Loss:   351.1271 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch   4 - Loss:   479.1758 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch   5 - Loss:   369.5032 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch   6 - Loss:   467.3814 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch   7 - Loss:   449.2878 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch   8 - Loss:   309.4264 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch   9 - Loss:   431.1847 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  10 - Loss:   248.7590 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  11 - Loss:   356.3474 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  12 - Loss:   358.4754 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  13 - Loss:   373.5075 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  14 - Loss:   590.4310 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  15 - Loss:   246.7688 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  16 - Loss:   506.7625 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  17 - Loss:   434.3416 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  18 - Loss:   242.6468 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  19 - Loss:   610.4864 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  20 - Loss:   468.9942 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  21 - Loss:   602.2694 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  22 - Loss:   420.7940 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  23 - Loss:   460.6148 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  24 - Loss:   234.8399 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  25 - Loss:   341.7340 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  26 - Loss:   456.1750 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  27 - Loss:   305.4839 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  28 - Loss:   360.7529 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  29 - Loss:   351.1459 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  30 - Loss:   700.3970 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  31 - Loss:   357.4211 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  32 - Loss:   409.1785 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  33 - Loss:   384.9531 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  34 - Loss:   370.0724 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  35 - Loss:   477.6809 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  36 - Loss:   303.9882 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  37 - Loss:   522.1250 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  38 - Loss:   490.5993 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  39 - Loss:   568.0929 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch  40 - Loss:   290.8266 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  41 - Loss:   331.9281 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  42 - Loss:   448.8664 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  43 - Loss:   556.6299 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  44 - Loss:   360.8013 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  45 - Loss:   378.3804 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  46 - Loss:   489.0057 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  47 - Loss:   261.2132 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  48 - Loss:   492.0345 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  49 - Loss:   398.3734 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  50 - Loss:   154.1733 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  51 - Loss:   395.1003 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  52 - Loss:   324.9996 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  53 - Loss:   243.1042 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  54 - Loss:   360.9008 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  55 - Loss:   276.5753 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  56 - Loss:   296.6427 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  57 - Loss:   559.6503 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  58 - Loss:   518.4089 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  59 - Loss:   177.5241 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  60 - Loss:   324.4774 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  61 - Loss:   408.0725 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  62 - Loss:   601.5923 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  63 - Loss:   372.5155 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  64 - Loss:   283.4801 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  65 - Loss:   227.1395 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  66 - Loss:   506.7934 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  67 - Loss:   404.8896 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  68 - Loss:   463.9969 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  69 - Loss:   510.1649 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  70 - Loss:   370.8583 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  71 - Loss:   327.2675 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  72 - Loss:   448.6638 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  73 - Loss:   386.5470 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  74 - Loss:   328.4582 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  75 - Loss:   302.3048 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  76 - Loss:   411.1602 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  77 - Loss:   437.6345 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  78 - Loss:   359.1579 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  79 - Loss:   464.4715 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  80 - Loss:   324.1429 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  81 - Loss:   384.0619 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  82 - Loss:   465.2910 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  83 - Loss:   512.9773 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  84 - Loss:   453.7846 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  85 - Loss:   303.2518 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  86 - Loss:   700.7357 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  87 - Loss:   293.4745 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  88 - Loss:   360.2826 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  89 - Loss:   274.8445 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  90 - Loss:   463.0670 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  91 - Loss:   417.7193 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch  92 - Loss:   376.3079 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  93 - Loss:   499.3295 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  94 - Loss:   510.7544 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  95 - Loss:   494.4042 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  96 - Loss:   436.4261 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch  97 - Loss:   426.3686 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  98 - Loss:   503.7311 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch  99 - Loss:   377.7284 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 100 - Loss:   324.9124 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 101 - Loss:   362.7979 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 102 - Loss:   298.0439 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 103 - Loss:   419.4184 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 104 - Loss:   288.8829 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 105 - Loss:   454.0856 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 106 - Loss:   317.4590 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 107 - Loss:   210.7601 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 108 - Loss:   542.1624 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 109 - Loss:   457.6736 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 110 - Loss:   561.3507 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 111 - Loss:   251.2173 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 112 - Loss:   482.0171 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 113 - Loss:   296.9474 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 114 - Loss:   573.2458 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 115 - Loss:   312.5727 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 116 - Loss:   397.0277 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 117 - Loss:   336.8572 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 118 - Loss:   375.9600 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 119 - Loss:   336.9437 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 120 - Loss:   201.0807 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 121 - Loss:   323.3453 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 122 - Loss:   286.6844 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 123 - Loss:   331.7219 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 124 - Loss:   511.5378 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 125 - Loss:   479.3176 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 126 - Loss:   315.6120 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 127 - Loss:   420.5280 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 128 - Loss:   559.8398 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 129 - Loss:   438.1866 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 130 - Loss:   458.9783 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 131 - Loss:   307.4214 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 132 - Loss:   527.4113 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 133 - Loss:   288.5012 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 134 - Loss:   331.4154 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 135 - Loss:   315.2650 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 136 - Loss:   449.7677 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 137 - Loss:   385.2427 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 138 - Loss:   427.2878 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 139 - Loss:   453.6230 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 140 - Loss:   277.4068 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 141 - Loss:   354.3847 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 142 - Loss:   283.3208 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 143 - Loss:   225.9137 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 144 - Loss:   447.5635 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 145 - Loss:   452.6446 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 146 - Loss:   248.1210 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 147 - Loss:   363.5656 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 148 - Loss:   470.4977 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 149 - Loss:   438.6413 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 150 - Loss:   446.8176 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 151 - Loss:   688.8025 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 152 - Loss:   369.4634 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 153 - Loss:   489.4099 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 154 - Loss:   458.3513 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 155 - Loss:   253.3641 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 156 - Loss:   557.9307 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 157 - Loss:   181.3922 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 158 - Loss:   279.8370 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 159 - Loss:   435.0302 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 160 - Loss:   442.3691 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 161 - Loss:   574.0577 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 162 - Loss:   321.4526 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 163 - Loss:   390.1681 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 164 - Loss:   348.0659 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 165 - Loss:   472.0673 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 166 - Loss:   209.9125 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 167 - Loss:   380.7827 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 168 - Loss:   432.6780 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 169 - Loss:   469.1130 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 170 - Loss:   356.3509 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 171 - Loss:   262.6196 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 172 - Loss:   438.1237 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 173 - Loss:   362.5848 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 174 - Loss:   373.6451 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 175 - Loss:   783.1780 Validation Accuracy: 0.863281\n",
      "Epoch  8, Batch 176 - Loss:   339.0493 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 177 - Loss:   331.1330 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 178 - Loss:   684.7812 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 179 - Loss:   441.1447 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 180 - Loss:   442.8582 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 181 - Loss:   155.8760 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 182 - Loss:   214.5649 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 183 - Loss:   338.5792 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 184 - Loss:   438.2474 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 185 - Loss:   307.6923 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 186 - Loss:   356.6059 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 187 - Loss:   372.7816 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 188 - Loss:   343.8865 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 189 - Loss:   364.1783 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 190 - Loss:   429.2283 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 191 - Loss:   434.6962 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 192 - Loss:   254.4361 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 193 - Loss:   582.6470 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 194 - Loss:   511.8862 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 195 - Loss:   407.1326 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 196 - Loss:   335.2771 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 197 - Loss:   370.4686 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 198 - Loss:   316.9709 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 199 - Loss:   329.4276 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 200 - Loss:   302.8725 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 201 - Loss:   521.6029 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 202 - Loss:   327.1102 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 203 - Loss:   344.8599 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 204 - Loss:   558.0861 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 205 - Loss:   291.0848 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 206 - Loss:   493.9518 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 207 - Loss:   257.7971 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 208 - Loss:   449.1658 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 209 - Loss:   419.5695 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 210 - Loss:   599.4343 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 211 - Loss:   319.4449 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 212 - Loss:   487.6566 Validation Accuracy: 0.863281\n",
      "Epoch  8, Batch 213 - Loss:   502.9527 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 214 - Loss:   469.2279 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 215 - Loss:   485.1804 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 216 - Loss:   388.6600 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 217 - Loss:   500.7465 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 218 - Loss:   304.6800 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 219 - Loss:   265.5724 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 220 - Loss:   444.5086 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 221 - Loss:   514.4029 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 222 - Loss:   301.7679 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 223 - Loss:   199.4469 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 224 - Loss:   235.3309 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 225 - Loss:   170.4975 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 226 - Loss:   450.8852 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 227 - Loss:   385.1539 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 228 - Loss:   499.1096 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 229 - Loss:   456.3030 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 230 - Loss:   235.4914 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 231 - Loss:   407.1567 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 232 - Loss:   500.9999 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 233 - Loss:   198.3357 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 234 - Loss:   526.9745 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 235 - Loss:   411.9748 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 236 - Loss:   378.5549 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 237 - Loss:   302.9757 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 238 - Loss:   148.5817 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 239 - Loss:   299.4897 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 240 - Loss:   341.2391 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 241 - Loss:   230.4236 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 242 - Loss:   302.8547 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 243 - Loss:   340.2285 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 244 - Loss:   315.2115 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 245 - Loss:   390.3229 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 246 - Loss:   488.6649 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 247 - Loss:   336.5969 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 248 - Loss:   247.5723 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 249 - Loss:   500.3053 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 250 - Loss:   403.6235 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 251 - Loss:   580.7856 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 252 - Loss:   482.1757 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 253 - Loss:   280.2833 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 254 - Loss:   300.2056 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 255 - Loss:   333.0140 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 256 - Loss:   380.7848 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 257 - Loss:   241.5894 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 258 - Loss:   580.2930 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 259 - Loss:   572.4613 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 260 - Loss:   259.1940 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 261 - Loss:   505.5664 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 262 - Loss:   382.9741 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 263 - Loss:   812.8619 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 264 - Loss:   293.6829 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 265 - Loss:   201.1590 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 266 - Loss:   313.0959 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 267 - Loss:   306.0590 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 268 - Loss:   325.7786 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 269 - Loss:   246.9895 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 270 - Loss:   306.7669 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 271 - Loss:   444.2564 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 272 - Loss:   722.1415 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 273 - Loss:   236.9184 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 274 - Loss:   263.1146 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 275 - Loss:   434.2894 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 276 - Loss:   339.7970 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 277 - Loss:   379.9580 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 278 - Loss:   361.8358 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 279 - Loss:   368.1580 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 280 - Loss:   366.5141 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 281 - Loss:   521.8308 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 282 - Loss:   396.2521 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 283 - Loss:   506.1855 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 284 - Loss:   246.6622 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 285 - Loss:   269.1420 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 286 - Loss:   263.2986 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 287 - Loss:   351.3236 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 288 - Loss:   430.9201 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 289 - Loss:   261.4313 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 290 - Loss:   333.6270 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 291 - Loss:   546.7908 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 292 - Loss:   272.6506 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 293 - Loss:   372.1035 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 294 - Loss:   426.4778 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 295 - Loss:   340.3653 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 296 - Loss:   282.1452 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 297 - Loss:   452.5953 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 298 - Loss:   424.4830 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 299 - Loss:   271.1171 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 300 - Loss:   522.9426 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 301 - Loss:   517.6969 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 302 - Loss:   223.4927 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 303 - Loss:   366.2472 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 304 - Loss:   520.6404 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 305 - Loss:   679.5731 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 306 - Loss:   512.7410 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 307 - Loss:   399.4926 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 308 - Loss:   291.5638 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 309 - Loss:   377.5266 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 310 - Loss:   540.1992 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 311 - Loss:   479.1211 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 312 - Loss:   373.7840 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 313 - Loss:   362.7268 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 314 - Loss:   339.6913 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 315 - Loss:   222.1323 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 316 - Loss:   352.0023 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 317 - Loss:   321.9486 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 318 - Loss:   394.1004 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 319 - Loss:   285.7614 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 320 - Loss:   401.7125 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 321 - Loss:   442.6075 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 322 - Loss:   338.5146 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 323 - Loss:   493.3084 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 324 - Loss:   330.8813 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 325 - Loss:   208.5857 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 326 - Loss:   215.3463 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 327 - Loss:   161.6129 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 328 - Loss:   292.3946 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 329 - Loss:   234.0240 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 330 - Loss:   318.4716 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 331 - Loss:   402.1436 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 332 - Loss:   204.8127 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 333 - Loss:   496.6211 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 334 - Loss:   726.3600 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 335 - Loss:   412.4319 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 336 - Loss:   266.3040 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 337 - Loss:   364.4240 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 338 - Loss:   411.6892 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 339 - Loss:   276.6679 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 340 - Loss:   403.9810 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 341 - Loss:   406.8382 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 342 - Loss:   220.9179 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 343 - Loss:   201.2780 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 344 - Loss:   367.9341 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 345 - Loss:   575.1810 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 346 - Loss:   392.3103 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 347 - Loss:   263.4396 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 348 - Loss:   261.3303 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 349 - Loss:   356.4721 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 350 - Loss:   392.7226 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 351 - Loss:   366.6202 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 352 - Loss:   329.2135 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 353 - Loss:   388.4425 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 354 - Loss:   311.4765 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 355 - Loss:   416.9829 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 356 - Loss:   156.7001 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 357 - Loss:   290.3318 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 358 - Loss:   411.8315 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 359 - Loss:   422.8528 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 360 - Loss:   335.1489 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 361 - Loss:   444.1693 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 362 - Loss:   270.6642 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 363 - Loss:   289.9163 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 364 - Loss:   287.0891 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 365 - Loss:   330.6884 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 366 - Loss:   359.4225 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 367 - Loss:   374.8274 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 368 - Loss:   148.2132 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 369 - Loss:   572.0160 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 370 - Loss:   698.6891 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 371 - Loss:   461.1801 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 372 - Loss:   496.3129 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 373 - Loss:   215.8599 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 374 - Loss:   361.1674 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 375 - Loss:   467.4492 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 376 - Loss:   389.1057 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 377 - Loss:   180.4682 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 378 - Loss:   340.3259 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 379 - Loss:   427.4467 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 380 - Loss:    88.2256 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 381 - Loss:   282.3019 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 382 - Loss:   417.6945 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 383 - Loss:   419.7402 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 384 - Loss:   391.4370 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 385 - Loss:   482.6883 Validation Accuracy: 0.839844\n",
      "Epoch  8, Batch 386 - Loss:   468.7338 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 387 - Loss:   546.0308 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 388 - Loss:   382.3466 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 389 - Loss:   248.9532 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 390 - Loss:   757.3615 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 391 - Loss:   628.2143 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 392 - Loss:   572.3227 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 393 - Loss:   181.5556 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 394 - Loss:   231.7117 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 395 - Loss:   241.8817 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 396 - Loss:   381.3142 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 397 - Loss:   279.5736 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 398 - Loss:   354.0267 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 399 - Loss:   618.1304 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 400 - Loss:   366.2765 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 401 - Loss:   485.2850 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 402 - Loss:   307.4825 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 403 - Loss:   352.2496 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 404 - Loss:   405.7433 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 405 - Loss:   377.0456 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 406 - Loss:   281.8763 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 407 - Loss:   469.7555 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 408 - Loss:   309.9475 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 409 - Loss:   477.9315 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 410 - Loss:   307.5673 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 411 - Loss:   382.3737 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 412 - Loss:   507.0767 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 413 - Loss:   461.2518 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 414 - Loss:   395.1174 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 415 - Loss:   415.6178 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 416 - Loss:   522.9390 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 417 - Loss:   270.4316 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 418 - Loss:   246.2253 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 419 - Loss:   422.9883 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 420 - Loss:   406.6049 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 421 - Loss:   405.0463 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 422 - Loss:   492.1349 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 423 - Loss:   260.5985 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 424 - Loss:   485.2428 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 425 - Loss:   183.7583 Validation Accuracy: 0.851562\n",
      "Epoch  8, Batch 426 - Loss:   321.2953 Validation Accuracy: 0.843750\n",
      "Epoch  8, Batch 427 - Loss:   219.0367 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 428 - Loss:   208.7530 Validation Accuracy: 0.847656\n",
      "Epoch  8, Batch 429 - Loss:   415.4804 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch   1 - Loss:   318.1054 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch   2 - Loss:   251.7264 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch   3 - Loss:   372.2859 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch   4 - Loss:   512.4714 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch   5 - Loss:   302.8580 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch   6 - Loss:   327.8318 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch   7 - Loss:   387.9778 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch   8 - Loss:   379.0071 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch   9 - Loss:   354.8825 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  10 - Loss:   564.7107 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  11 - Loss:   285.8826 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  12 - Loss:   217.4124 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  13 - Loss:   406.3280 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  14 - Loss:   460.9534 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  15 - Loss:   558.3998 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  16 - Loss:   350.9496 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  17 - Loss:   326.4142 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  18 - Loss:   440.7247 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  19 - Loss:   391.2393 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  20 - Loss:   326.3485 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  21 - Loss:   294.8130 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  22 - Loss:   469.2448 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  23 - Loss:   334.8140 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  24 - Loss:   298.5858 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  25 - Loss:   373.0496 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  26 - Loss:   361.6450 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  27 - Loss:   494.5032 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  28 - Loss:   416.9843 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  29 - Loss:   470.0402 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  30 - Loss:   370.2245 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  31 - Loss:   418.5471 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  32 - Loss:   292.0913 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  33 - Loss:   126.5009 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  34 - Loss:   242.0788 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  35 - Loss:   534.0413 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  36 - Loss:   256.7243 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  37 - Loss:   247.7554 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  38 - Loss:   340.4484 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  39 - Loss:   472.3674 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  40 - Loss:   165.0679 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  41 - Loss:   369.0530 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  42 - Loss:   376.9484 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  43 - Loss:   340.9060 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  44 - Loss:   277.1292 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  45 - Loss:   378.6695 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  46 - Loss:   398.0888 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  47 - Loss:   380.4195 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  48 - Loss:   480.3910 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  49 - Loss:   266.3685 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  50 - Loss:   195.9009 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  51 - Loss:   497.4813 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  52 - Loss:   359.4555 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  53 - Loss:   265.1688 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  54 - Loss:   207.4840 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  55 - Loss:   219.0811 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  56 - Loss:   527.2177 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  57 - Loss:   344.8087 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  58 - Loss:   299.3911 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  59 - Loss:   189.2722 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  60 - Loss:   502.1781 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  61 - Loss:   239.1231 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  62 - Loss:   404.2952 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  63 - Loss:   386.9501 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  64 - Loss:   495.4979 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch  65 - Loss:   612.6348 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  66 - Loss:   365.0219 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  67 - Loss:   474.0521 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  68 - Loss:   255.6534 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  69 - Loss:   311.3770 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  70 - Loss:   456.5099 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  71 - Loss:   509.1176 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  72 - Loss:   259.8972 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  73 - Loss:   386.0455 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  74 - Loss:   360.3799 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  75 - Loss:   520.2069 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  76 - Loss:   290.5990 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  77 - Loss:   466.4377 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  78 - Loss:   235.2920 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  79 - Loss:   262.6917 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  80 - Loss:   302.1694 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  81 - Loss:   401.7126 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  82 - Loss:   228.7504 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  83 - Loss:   436.6790 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  84 - Loss:   425.6866 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  85 - Loss:   347.1404 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  86 - Loss:   536.8701 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  87 - Loss:   253.3849 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  88 - Loss:   433.5802 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch  89 - Loss:   303.0416 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  90 - Loss:   505.1532 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  91 - Loss:   290.6410 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  92 - Loss:   338.3756 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  93 - Loss:   538.0062 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  94 - Loss:   432.7183 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch  95 - Loss:   339.7803 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch  96 - Loss:   230.2134 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch  97 - Loss:   520.8786 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  98 - Loss:   210.1258 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  99 - Loss:   329.3129 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 100 - Loss:   520.7127 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 101 - Loss:   305.5772 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 102 - Loss:   221.6005 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 103 - Loss:   447.2525 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 104 - Loss:   350.9506 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 105 - Loss:   264.6982 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 106 - Loss:   373.8920 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 107 - Loss:   433.0523 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 108 - Loss:   422.4019 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 109 - Loss:   303.6079 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 110 - Loss:   423.8552 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 111 - Loss:   260.7805 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 112 - Loss:   268.1051 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 113 - Loss:   383.3099 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 114 - Loss:   323.2990 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 115 - Loss:   374.5643 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 116 - Loss:   538.4509 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 117 - Loss:   371.2345 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 118 - Loss:   361.8658 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 119 - Loss:   224.9386 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 120 - Loss:   389.9793 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 121 - Loss:   296.6557 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 122 - Loss:   345.0239 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 123 - Loss:   256.9836 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 124 - Loss:   311.3971 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 125 - Loss:   271.8626 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 126 - Loss:   320.0421 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 127 - Loss:   483.7585 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 128 - Loss:   343.9461 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 129 - Loss:   483.3624 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 130 - Loss:   357.9309 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 131 - Loss:   357.4395 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 132 - Loss:   294.8412 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 133 - Loss:   398.7416 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 134 - Loss:   325.6753 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 135 - Loss:   245.7417 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 136 - Loss:   414.2366 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 137 - Loss:   684.8626 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 138 - Loss:   510.8252 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 139 - Loss:   381.7375 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 140 - Loss:   354.4053 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 141 - Loss:   257.7928 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 142 - Loss:   334.3987 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 143 - Loss:   472.1895 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 144 - Loss:   297.1126 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 145 - Loss:   456.9676 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 146 - Loss:   448.8428 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 147 - Loss:   621.5531 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 148 - Loss:   356.8538 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 149 - Loss:   565.1515 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 150 - Loss:   371.3184 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 151 - Loss:   566.5646 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 152 - Loss:   290.4070 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 153 - Loss:   154.8648 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 154 - Loss:   295.1237 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 155 - Loss:   473.6536 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 156 - Loss:   248.6535 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 157 - Loss:   465.7972 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 158 - Loss:   425.5466 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 159 - Loss:   200.2238 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 160 - Loss:   276.9751 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 161 - Loss:   407.7599 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 162 - Loss:   275.9587 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 163 - Loss:   374.9187 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 164 - Loss:   428.2706 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 165 - Loss:   338.6331 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 166 - Loss:   349.7123 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 167 - Loss:   432.8814 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 168 - Loss:   481.5714 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 169 - Loss:   182.8544 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 170 - Loss:   413.2310 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 171 - Loss:   331.4299 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 172 - Loss:   423.9592 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 173 - Loss:   483.0276 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 174 - Loss:   297.9641 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 175 - Loss:   281.9489 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 176 - Loss:   254.2384 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 177 - Loss:   275.3504 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 178 - Loss:   406.2526 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 179 - Loss:   463.5755 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 180 - Loss:   325.0787 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 181 - Loss:   360.4552 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 182 - Loss:   569.2047 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 183 - Loss:   243.5247 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 184 - Loss:   215.2050 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 185 - Loss:   313.7082 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 186 - Loss:   311.7852 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 187 - Loss:   489.8883 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 188 - Loss:   579.6113 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 189 - Loss:   428.4886 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 190 - Loss:   217.0247 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 191 - Loss:   644.4512 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 192 - Loss:   429.4051 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 193 - Loss:   505.1835 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 194 - Loss:   313.7675 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 195 - Loss:   402.8617 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 196 - Loss:   325.8817 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 197 - Loss:   186.1757 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 198 - Loss:   350.6011 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 199 - Loss:   564.2571 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 200 - Loss:   324.2586 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 201 - Loss:   312.6638 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 202 - Loss:   331.3879 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 203 - Loss:   341.3606 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 204 - Loss:   489.9569 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 205 - Loss:   322.1070 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 206 - Loss:   145.8001 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 207 - Loss:   459.0909 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 208 - Loss:   458.4195 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 209 - Loss:   282.1213 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 210 - Loss:   310.3987 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 211 - Loss:   269.3060 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 212 - Loss:   371.5419 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 213 - Loss:   268.5883 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 214 - Loss:   204.8006 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 215 - Loss:   282.4374 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 216 - Loss:   338.9304 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 217 - Loss:   244.7057 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 218 - Loss:   330.8782 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 219 - Loss:   227.7781 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 220 - Loss:   344.3305 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 221 - Loss:   502.9562 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 222 - Loss:   320.7967 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 223 - Loss:   290.6087 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 224 - Loss:   355.9380 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 225 - Loss:   354.8366 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 226 - Loss:   280.4384 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 227 - Loss:   268.2143 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 228 - Loss:   351.6035 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 229 - Loss:   314.6829 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 230 - Loss:   341.4034 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 231 - Loss:   382.7452 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 232 - Loss:   271.4312 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 233 - Loss:   384.7976 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 234 - Loss:   361.5495 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 235 - Loss:   342.1472 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 236 - Loss:   477.2499 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 237 - Loss:   296.0126 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 238 - Loss:   377.2408 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 239 - Loss:   198.3792 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 240 - Loss:   373.6276 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 241 - Loss:   498.0919 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 242 - Loss:   265.3214 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 243 - Loss:   392.1815 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 244 - Loss:   220.6614 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 245 - Loss:   405.4699 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 246 - Loss:   224.4640 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 247 - Loss:   374.6580 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 248 - Loss:   287.0532 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 249 - Loss:   435.5143 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 250 - Loss:   336.5918 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 251 - Loss:   625.7717 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 252 - Loss:   365.4773 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 253 - Loss:   390.1907 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 254 - Loss:   459.1574 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 255 - Loss:   581.5352 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 256 - Loss:   422.0968 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 257 - Loss:   286.2412 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 258 - Loss:   430.2032 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 259 - Loss:   529.1121 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 260 - Loss:   422.7473 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 261 - Loss:   484.1261 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 262 - Loss:   406.4684 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 263 - Loss:   315.2556 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 264 - Loss:   460.8933 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 265 - Loss:   295.4388 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 266 - Loss:   349.8534 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 267 - Loss:   294.6255 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 268 - Loss:   497.4106 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 269 - Loss:   213.8107 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 270 - Loss:   235.5329 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 271 - Loss:   410.1349 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 272 - Loss:   212.4530 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 273 - Loss:   343.6214 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 274 - Loss:   374.9451 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 275 - Loss:   414.5642 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 276 - Loss:   353.6933 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 277 - Loss:   253.8011 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 278 - Loss:   427.8539 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 279 - Loss:   273.5512 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 280 - Loss:   201.8783 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 281 - Loss:   618.1608 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 282 - Loss:   246.2300 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 283 - Loss:   304.9675 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 284 - Loss:   196.1364 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 285 - Loss:   298.8736 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 286 - Loss:   357.8785 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 287 - Loss:   349.1281 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 288 - Loss:   295.0855 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 289 - Loss:   232.7651 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 290 - Loss:   203.9376 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 291 - Loss:   564.0704 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 292 - Loss:   265.7101 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 293 - Loss:   456.2466 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 294 - Loss:   400.2504 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 295 - Loss:   299.3210 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 296 - Loss:   297.5475 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 297 - Loss:   259.4160 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 298 - Loss:   325.3582 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 299 - Loss:   523.3200 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 300 - Loss:   191.5930 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 301 - Loss:   190.1954 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 302 - Loss:   343.8567 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 303 - Loss:   274.8785 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 304 - Loss:   214.7617 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 305 - Loss:   472.4215 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 306 - Loss:   519.0146 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 307 - Loss:   447.8535 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 308 - Loss:   517.9374 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 309 - Loss:   301.3619 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 310 - Loss:   335.8533 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 311 - Loss:   128.6889 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 312 - Loss:   220.2240 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 313 - Loss:   513.4618 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 314 - Loss:   378.4405 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 315 - Loss:   437.4163 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 316 - Loss:   405.1337 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 317 - Loss:   159.8444 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 318 - Loss:   178.8861 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 319 - Loss:   353.8677 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 320 - Loss:   367.2738 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 321 - Loss:   229.7627 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 322 - Loss:   236.7473 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 323 - Loss:   288.2921 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 324 - Loss:   405.9867 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 325 - Loss:   190.9916 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 326 - Loss:   186.2292 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 327 - Loss:   349.7649 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 328 - Loss:   382.3716 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 329 - Loss:   415.8456 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 330 - Loss:   441.1500 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 331 - Loss:   409.3052 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 332 - Loss:   253.8436 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 333 - Loss:   468.4603 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 334 - Loss:   254.9831 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 335 - Loss:   480.5453 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 336 - Loss:   350.7730 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 337 - Loss:   238.6657 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 338 - Loss:   463.0305 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 339 - Loss:   368.6317 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 340 - Loss:   367.6695 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 341 - Loss:   233.7159 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 342 - Loss:   600.0295 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 343 - Loss:   404.7816 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 344 - Loss:   371.1964 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 345 - Loss:   437.2365 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 346 - Loss:   308.9285 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 347 - Loss:   276.0670 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 348 - Loss:   320.5441 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 349 - Loss:   248.3111 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 350 - Loss:   309.8102 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 351 - Loss:   313.0697 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 352 - Loss:   283.2793 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 353 - Loss:   500.3954 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 354 - Loss:   299.0626 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 355 - Loss:   404.5413 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 356 - Loss:   485.0497 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 357 - Loss:   266.5065 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 358 - Loss:   479.9832 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 359 - Loss:   332.6482 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 360 - Loss:   409.3610 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 361 - Loss:   223.8328 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 362 - Loss:   453.5775 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 363 - Loss:   370.2313 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 364 - Loss:   454.3827 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 365 - Loss:   229.7239 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 366 - Loss:   344.0021 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 367 - Loss:   213.6495 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 368 - Loss:   350.6498 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 369 - Loss:   316.2762 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 370 - Loss:   243.8270 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 371 - Loss:   180.1753 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 372 - Loss:   352.2906 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 373 - Loss:   346.3961 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 374 - Loss:   289.5314 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 375 - Loss:   182.1753 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 376 - Loss:   359.4552 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 377 - Loss:   388.3147 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 378 - Loss:   366.8836 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 379 - Loss:   425.5378 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 380 - Loss:   178.4672 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 381 - Loss:   249.4310 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 382 - Loss:   263.7530 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 383 - Loss:   519.1608 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 384 - Loss:   317.1412 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 385 - Loss:   302.8495 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 386 - Loss:   369.1901 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 387 - Loss:   450.3282 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 388 - Loss:   330.5248 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 389 - Loss:   243.1896 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 390 - Loss:   198.2160 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 391 - Loss:   288.8205 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 392 - Loss:   400.8821 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 393 - Loss:   146.3907 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 394 - Loss:   466.9506 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 395 - Loss:   403.6065 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 396 - Loss:   243.8051 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 397 - Loss:   296.2945 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 398 - Loss:   139.6288 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 399 - Loss:   267.4038 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 400 - Loss:   331.3519 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 401 - Loss:   249.0416 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 402 - Loss:   440.2977 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 403 - Loss:   331.9066 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 404 - Loss:   198.8513 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 405 - Loss:   292.2051 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 406 - Loss:   325.9479 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 407 - Loss:   240.9344 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 408 - Loss:   354.4540 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 409 - Loss:   372.9288 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 410 - Loss:   189.1608 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 411 - Loss:   322.7453 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 412 - Loss:   361.3314 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 413 - Loss:   329.2365 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 414 - Loss:   274.6230 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 415 - Loss:   175.9741 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 416 - Loss:   284.6602 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 417 - Loss:   341.5759 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 418 - Loss:   219.0433 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 419 - Loss:   314.4185 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 420 - Loss:   371.6267 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 421 - Loss:   371.0578 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 422 - Loss:   307.6307 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 423 - Loss:   401.3628 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 424 - Loss:   241.6188 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 425 - Loss:   177.6095 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 426 - Loss:   280.4417 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 427 - Loss:   482.5896 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch 428 - Loss:   519.7651 Validation Accuracy: 0.847656\n",
      "Epoch  9, Batch 429 - Loss:   451.3699 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch   1 - Loss:   327.9707 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch   2 - Loss:   459.2977 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch   3 - Loss:   359.3484 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch   4 - Loss:   271.9823 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch   5 - Loss:   621.9944 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch   6 - Loss:   502.6456 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch   7 - Loss:   352.2335 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch   8 - Loss:   427.2656 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch   9 - Loss:   532.5388 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  10 - Loss:   223.3929 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  11 - Loss:   375.3201 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  12 - Loss:   548.0354 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  13 - Loss:   258.6772 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  14 - Loss:   273.6516 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  15 - Loss:   371.1369 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  16 - Loss:   237.9369 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  17 - Loss:   437.8094 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  18 - Loss:   262.0807 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  19 - Loss:   198.8133 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  20 - Loss:   282.7702 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  21 - Loss:   145.4801 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  22 - Loss:   398.9184 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  23 - Loss:   273.4564 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  24 - Loss:   488.0062 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  25 - Loss:   207.2908 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  26 - Loss:   155.0119 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  27 - Loss:   466.4336 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  28 - Loss:   138.2076 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  29 - Loss:   339.4629 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  30 - Loss:   341.0072 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  31 - Loss:   145.2277 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  32 - Loss:   330.6223 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  33 - Loss:   332.7643 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  34 - Loss:   214.6918 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  35 - Loss:   250.5756 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  36 - Loss:   344.0586 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  37 - Loss:   342.1803 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  38 - Loss:   274.6967 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  39 - Loss:   344.2761 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  40 - Loss:   368.5189 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  41 - Loss:   156.1569 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  42 - Loss:   515.3383 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  43 - Loss:   294.7989 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  44 - Loss:   256.9114 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  45 - Loss:   504.1426 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  46 - Loss:   358.6220 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  47 - Loss:   426.2001 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  48 - Loss:   367.5418 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  49 - Loss:   479.8522 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  50 - Loss:   323.3237 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  51 - Loss:   270.7328 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  52 - Loss:   307.1895 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  53 - Loss:   340.7480 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  54 - Loss:   234.4794 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  55 - Loss:   308.9487 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  56 - Loss:   324.4443 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  57 - Loss:   367.7206 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  58 - Loss:   230.1848 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  59 - Loss:   259.0878 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  60 - Loss:   295.9220 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  61 - Loss:   435.4560 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  62 - Loss:   369.4481 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  63 - Loss:   231.2210 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  64 - Loss:   272.5251 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  65 - Loss:   347.0107 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  66 - Loss:   647.0602 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  67 - Loss:   333.6375 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  68 - Loss:   370.2641 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  69 - Loss:   412.4867 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  70 - Loss:   181.1376 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch  71 - Loss:   386.8375 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  72 - Loss:   385.4084 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  73 - Loss:   249.3340 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  74 - Loss:   622.9591 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  75 - Loss:   319.0794 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  76 - Loss:   406.1509 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  77 - Loss:   399.5970 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch  78 - Loss:   428.4171 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  79 - Loss:   553.7256 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  80 - Loss:   437.2414 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  81 - Loss:   119.0800 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  82 - Loss:   356.6087 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  83 - Loss:   194.9093 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  84 - Loss:   400.1876 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  85 - Loss:   400.2976 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  86 - Loss:   333.8161 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  87 - Loss:   548.1021 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  88 - Loss:   253.6617 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  89 - Loss:   398.9521 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  90 - Loss:   296.0472 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  91 - Loss:   293.1492 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  92 - Loss:   328.7527 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  93 - Loss:   294.0384 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  94 - Loss:   336.3017 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  95 - Loss:   160.3100 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  96 - Loss:   339.8129 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch  97 - Loss:   198.7451 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  98 - Loss:   329.4937 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  99 - Loss:   296.6982 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 100 - Loss:   239.3096 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 101 - Loss:   247.5962 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 102 - Loss:   350.8205 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 103 - Loss:   336.7630 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 104 - Loss:   293.0111 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 105 - Loss:   359.9787 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 106 - Loss:   209.1148 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 107 - Loss:   252.4432 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 108 - Loss:   289.2199 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 109 - Loss:   295.8386 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 110 - Loss:   334.3873 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 111 - Loss:   262.2460 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 112 - Loss:   317.0591 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 113 - Loss:   289.6223 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 114 - Loss:   350.9677 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 115 - Loss:   394.4607 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 116 - Loss:   376.0141 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 117 - Loss:   608.2386 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 118 - Loss:   221.0092 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 119 - Loss:   520.1258 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 120 - Loss:   289.1175 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 121 - Loss:   292.1387 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 122 - Loss:   255.4424 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 123 - Loss:   427.8694 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 124 - Loss:   440.0129 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 125 - Loss:   415.9344 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 126 - Loss:   376.6597 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 127 - Loss:   493.7908 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 128 - Loss:   374.4228 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 129 - Loss:   559.9448 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 130 - Loss:   292.5358 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 131 - Loss:   410.1409 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 132 - Loss:   200.9494 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 133 - Loss:   414.4902 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 134 - Loss:   352.4101 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 135 - Loss:   289.0144 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 136 - Loss:   199.1431 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 137 - Loss:   431.0452 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 138 - Loss:   233.5863 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 139 - Loss:   251.0181 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 140 - Loss:   207.3175 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 141 - Loss:   287.8498 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 142 - Loss:   263.3394 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 143 - Loss:   136.5768 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 144 - Loss:   241.3034 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 145 - Loss:   294.6439 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 146 - Loss:   319.0370 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 147 - Loss:   250.1606 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 148 - Loss:   332.2401 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 149 - Loss:   517.7376 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 150 - Loss:   359.7005 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 151 - Loss:   469.8945 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 152 - Loss:   170.2231 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 153 - Loss:   218.2498 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 154 - Loss:   173.4875 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 155 - Loss:   396.0115 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 156 - Loss:   259.7689 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 157 - Loss:   358.2398 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 158 - Loss:   157.5052 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 159 - Loss:   312.5226 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 160 - Loss:   289.4830 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 161 - Loss:   344.2559 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 162 - Loss:   372.0562 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 163 - Loss:   343.3176 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 164 - Loss:   315.3677 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 165 - Loss:   354.5364 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 166 - Loss:   305.2967 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 167 - Loss:   484.7468 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 168 - Loss:   236.0108 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 169 - Loss:   309.2682 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 170 - Loss:   253.5248 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 171 - Loss:   316.8851 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 172 - Loss:   409.2854 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 173 - Loss:   331.1411 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 174 - Loss:   352.5747 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 175 - Loss:   169.4600 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 176 - Loss:   271.4266 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 177 - Loss:   304.6498 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 178 - Loss:   257.4097 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 179 - Loss:   266.5885 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 180 - Loss:   217.7992 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 181 - Loss:   265.6398 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 182 - Loss:   245.7980 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 183 - Loss:   200.3179 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 184 - Loss:   356.4104 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 185 - Loss:   248.3856 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 186 - Loss:   225.0129 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 187 - Loss:   316.9501 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 188 - Loss:   278.4847 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 189 - Loss:   286.9011 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 190 - Loss:   356.3659 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 191 - Loss:   270.9234 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 192 - Loss:   217.1557 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 193 - Loss:   201.2934 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 194 - Loss:   280.0207 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 195 - Loss:   328.6557 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 196 - Loss:   315.7211 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 197 - Loss:   275.5674 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 198 - Loss:   246.4314 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 199 - Loss:   242.1205 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 200 - Loss:   391.8756 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 201 - Loss:   327.7521 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 202 - Loss:   473.8801 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 203 - Loss:   270.4242 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 204 - Loss:   284.6609 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 205 - Loss:   457.9668 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 206 - Loss:   269.3146 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 207 - Loss:   204.4810 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 208 - Loss:   304.8139 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 209 - Loss:   338.0013 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 210 - Loss:   319.9902 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 211 - Loss:   283.5155 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 212 - Loss:   331.4826 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 213 - Loss:   342.4464 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 214 - Loss:   314.7130 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 215 - Loss:   414.9337 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 216 - Loss:   361.6068 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 217 - Loss:   354.6415 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 218 - Loss:   278.7908 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 219 - Loss:   253.2331 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 220 - Loss:   269.4575 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 221 - Loss:   393.9628 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 222 - Loss:   234.3661 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 223 - Loss:   334.0463 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 224 - Loss:   341.7091 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 225 - Loss:   441.5261 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 226 - Loss:   342.2910 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 227 - Loss:   417.2464 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 228 - Loss:   416.1090 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 229 - Loss:   254.5613 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 230 - Loss:   289.0675 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 231 - Loss:   358.1923 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 232 - Loss:   442.2412 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 233 - Loss:   217.1545 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 234 - Loss:   201.0872 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 235 - Loss:   199.4438 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 236 - Loss:   228.6907 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 237 - Loss:   271.3467 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 238 - Loss:   288.2432 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 239 - Loss:   291.2028 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 240 - Loss:   391.6048 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 241 - Loss:   317.5690 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 242 - Loss:   235.5450 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 243 - Loss:   219.5525 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 244 - Loss:   289.9333 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 245 - Loss:   336.9465 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 246 - Loss:   231.7704 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 247 - Loss:   426.8901 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 248 - Loss:   255.6966 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 249 - Loss:   163.7861 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 250 - Loss:   193.1068 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 251 - Loss:   328.7112 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 252 - Loss:   419.8260 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 253 - Loss:   355.9303 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 254 - Loss:   337.9516 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 255 - Loss:   308.2840 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 256 - Loss:   428.0020 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 257 - Loss:   419.6975 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 258 - Loss:   406.2159 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 259 - Loss:   470.7106 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 260 - Loss:   421.8317 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 261 - Loss:   509.6974 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 262 - Loss:   373.5851 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 263 - Loss:   257.7222 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 264 - Loss:   376.0247 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 265 - Loss:   255.9078 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 266 - Loss:   326.4850 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 267 - Loss:   317.2810 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 268 - Loss:   116.1650 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 269 - Loss:   237.6926 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 270 - Loss:   399.5959 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 271 - Loss:   295.9460 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 272 - Loss:   482.4835 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 273 - Loss:   215.4334 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 274 - Loss:   219.5563 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 275 - Loss:   389.9324 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 276 - Loss:   261.3607 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 277 - Loss:   296.6501 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 278 - Loss:   259.4426 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 279 - Loss:   321.2932 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 280 - Loss:   246.2625 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 281 - Loss:   355.0964 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 282 - Loss:   248.4321 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 283 - Loss:   537.3474 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 284 - Loss:   178.6341 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 285 - Loss:   296.4613 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 286 - Loss:   420.8951 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 287 - Loss:   240.6194 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 288 - Loss:   415.5710 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 289 - Loss:   154.1123 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 290 - Loss:   218.9337 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 291 - Loss:   233.2874 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 292 - Loss:   659.3728 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 293 - Loss:   341.5688 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 294 - Loss:   285.1563 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 295 - Loss:   245.5232 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 296 - Loss:   265.2137 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 297 - Loss:   411.0722 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 298 - Loss:   363.1686 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 299 - Loss:   194.7169 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 300 - Loss:   229.4837 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 301 - Loss:   314.3978 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 302 - Loss:   234.4857 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 303 - Loss:   265.8687 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 304 - Loss:   222.7432 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 305 - Loss:   416.8960 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 306 - Loss:   352.5645 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 307 - Loss:   374.4891 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 308 - Loss:   242.9902 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 309 - Loss:   220.0003 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 310 - Loss:   342.5605 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 311 - Loss:   323.8648 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 312 - Loss:   325.3657 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 313 - Loss:   290.0598 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 314 - Loss:   280.8427 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 315 - Loss:   481.2162 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 316 - Loss:   424.6265 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 317 - Loss:   220.2284 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 318 - Loss:   382.0385 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 319 - Loss:   183.4440 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 320 - Loss:   314.4329 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 321 - Loss:   263.3789 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 322 - Loss:   201.6700 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 323 - Loss:   259.8610 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 324 - Loss:   347.9254 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 325 - Loss:   269.3824 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 326 - Loss:   320.6099 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 327 - Loss:   374.6084 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 328 - Loss:   285.2468 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 329 - Loss:   176.2133 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 330 - Loss:   226.8744 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 331 - Loss:   432.5171 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 332 - Loss:   349.4285 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 333 - Loss:   212.2976 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 334 - Loss:   294.2868 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 335 - Loss:   410.6937 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 336 - Loss:   261.9954 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 337 - Loss:   310.2151 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 338 - Loss:   381.4883 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 339 - Loss:   613.6371 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch 340 - Loss:   485.7977 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 341 - Loss:   286.4213 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 342 - Loss:   399.0092 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 343 - Loss:   345.8559 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 344 - Loss:   375.1828 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 345 - Loss:   489.0137 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 346 - Loss:   492.0168 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 347 - Loss:   303.4023 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 348 - Loss:   395.7887 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 349 - Loss:   351.1174 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 350 - Loss:   350.4912 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 351 - Loss:   400.0991 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 352 - Loss:   255.5245 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 353 - Loss:   408.5153 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 354 - Loss:   383.8521 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 355 - Loss:   280.4164 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 356 - Loss:   282.0067 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 357 - Loss:   304.4462 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 358 - Loss:   363.7628 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 359 - Loss:   443.3899 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 360 - Loss:   380.3606 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 361 - Loss:   208.3773 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 362 - Loss:   477.5159 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 363 - Loss:   242.0838 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 364 - Loss:   262.5772 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 365 - Loss:   195.9333 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 366 - Loss:   219.9626 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 367 - Loss:   269.6371 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 368 - Loss:   250.0838 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 369 - Loss:   331.7106 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 370 - Loss:   238.4238 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 371 - Loss:   352.6667 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 372 - Loss:   325.0494 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 373 - Loss:   473.7243 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 374 - Loss:   227.0655 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 375 - Loss:   492.7807 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 376 - Loss:   303.5154 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 377 - Loss:   474.6411 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 378 - Loss:   221.0894 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 379 - Loss:   276.2241 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 380 - Loss:   455.7307 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 381 - Loss:   432.8546 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 382 - Loss:   364.0572 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 383 - Loss:   377.7749 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 384 - Loss:   152.9009 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 385 - Loss:   406.4036 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 386 - Loss:   410.1118 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 387 - Loss:   142.4668 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 388 - Loss:   453.0599 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 389 - Loss:   265.3037 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 390 - Loss:   216.9472 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 391 - Loss:   311.6091 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 392 - Loss:   228.9050 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 393 - Loss:   313.6703 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 394 - Loss:   470.2661 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 395 - Loss:   565.1285 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 396 - Loss:   459.3232 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 397 - Loss:   136.6036 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 398 - Loss:   360.2525 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 399 - Loss:   252.7604 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 400 - Loss:   195.6325 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 401 - Loss:   203.2735 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 402 - Loss:   387.3064 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 403 - Loss:   303.3940 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 404 - Loss:   401.1284 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 405 - Loss:   313.2837 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 406 - Loss:   358.2659 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 407 - Loss:   296.7822 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 408 - Loss:   180.9311 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 409 - Loss:   328.3953 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 410 - Loss:   281.5547 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 411 - Loss:   255.2767 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 412 - Loss:   297.4491 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 413 - Loss:   227.6169 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 414 - Loss:   310.2709 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 415 - Loss:   346.3380 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 416 - Loss:   191.3712 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 417 - Loss:   385.2384 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 418 - Loss:   573.7437 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 419 - Loss:   324.7278 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 420 - Loss:    88.8771 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 421 - Loss:   359.2529 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 422 - Loss:   336.9359 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 423 - Loss:   315.5476 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 424 - Loss:   490.6553 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 425 - Loss:   322.3267 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 426 - Loss:   227.7732 Validation Accuracy: 0.847656\n",
      "Epoch 10, Batch 427 - Loss:   321.1970 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 428 - Loss:   199.7738 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 429 - Loss:   252.5210 Validation Accuracy: 0.843750\n",
      "Testing Accuracy: 0.8828125\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
